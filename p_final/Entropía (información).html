<!DOCTYPE html>
<!-- saved from url=(0062)https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n) -->
<html class="client-js ve-not-available" lang="es" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Entropía (información) - Wikipedia, la enciclopedia libre</title>
<link rel="stylesheet" crossorigin="anonymous" href="./Entropía (información)_files/main.css"><script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Entropía_(información)","wgTitle":"Entropía (información)","wgCurRevisionId":103374672,"wgRevisionId":103374672,"wgArticleId":1166274,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Entropía de la información","Teoría de la información"],"wgBreakFrames":false,"wgPageContentLanguage":"es","wgPageContentModel":"wikitext","wgSeparatorTransformTable":[",\t."," \t,"],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","enero","febrero","marzo","abril","mayo","junio","julio","agosto","septiembre","octubre","noviembre","diciembre"],"wgMonthNamesShort":["","ene","feb","mar","abr","may","jun","jul","ago","sep","oct","nov","dic"],"wgRelevantPageName":"Entropía_(información)","wgRelevantArticleId":1166274,"wgRequestId":"Wi2-JgpAICgAACOBboQAAADD","wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgWikiEditorEnabledModules":{"toolbar":true,"preview":false,"publish":false},"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsShouldSendModuleToUser":true,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"es","pageLanguageDir":"ltr","pageVariantFallbacks":"es","usePageImages":true,"usePageDescriptions":true},"wgPreferredVariant":"es","wgMFExpandAllSectionsUserOption":false,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":true},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgULSCurrentAutonym":"español","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikibaseItemId":"Q204570","wgCentralAuthMobileDomain":false,"wgCodeMirrorEnabled":false,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":true});mw.loader.state({"ext.gadget.imagenesinfobox":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","user":"ready","user.options":"loading","user.tokens":"loading","ext.math.styles":"ready","ext.cite.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready"});mw.loader.implement("user.options@0qprsob",function($,jQuery,require,module){mw.user.options.set({"variant":"es"});});mw.loader.implement("user.tokens@1dqfd7l",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/

});mw.loader.load(["ext.math.scripts","ext.cite.a11y","site","mediawiki.page.startup","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.a-commons-directo","ext.gadget.refToolbar","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging.subscriber","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.compactlinks","ext.uls.interface","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"]);});</script>
<link rel="stylesheet" href="./Entropía (información)_files/load.php">
<script async="" src="./Entropía (información)_files/load(1).php"></script>
<style>
.cite-accessibility-label{ top:-99999px;clip:rect( 1px 1px 1px 1px ); clip:rect( 1px,1px,1px,1px ); position:absolute !important;padding:0 !important;border:0 !important;height:1px !important;width:1px !important; overflow:hidden}
@media screen {
	.tochidden,.toctoggle{-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.toctoggle{font-size:94%}}
@media print {
	#toc.tochidden,.toc.tochidden,.toctoggle{display:none}}
@-webkit-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-webkit-transform:translateY( -20px )}100%{opacity:1;-webkit-transform:translateY( 0 )}}@-moz-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-moz-transform:translateY( -20px )}100%{opacity:1;-moz-transform:translateY( 0 )}}@-o-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-o-transform:translateY( -20px )}100%{opacity:1;-o-transform:translateY( 0 )}}@keyframes centralAuthPPersonalAnimation{0%{opacity:0;transform:translateY( -20px )}100%{opacity:1;transform:translateY( 0 )}}.centralAuthPPersonalAnimation{-webkit-animation-duration:1s;-moz-animation-duration:1s;-o-animation-duration:1s;animation-duration:1s;-webkit-animation-fill-mode:both;-moz-animation-fill-mode:both;-o-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-name:centralAuthPPersonalAnimation;-moz-animation-name:centralAuthPPersonalAnimation;-o-animation-name:centralAuthPPersonalAnimation;animation-name:centralAuthPPersonalAnimation}
.ve-activated #toc,.ve-activated #siteNotice,.ve-activated .mw-indicators,.ve-activated #t-print,.ve-activated #t-permalink,.ve-activated #p-coll-print_export,.ve-activated #t-cite,.ve-deactivating .ve-ui-surface,.ve-active .ve-init-mw-desktopArticleTarget-editableContent{display:none} .ve-activating .ve-ui-surface{height:0;padding:0 !important; overflow:hidden} .ve-loading #content > :not( .ve-init-mw-desktopArticleTarget-loading-overlay ), .ve-activated .ve-init-mw-desktopArticleTarget-uneditableContent{ pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;opacity:0.5}.ve-activated #catlinks{cursor:pointer}.ve-activated #catlinks a{opacity:1} .ve-activated #content{position:relative} .ve-init-mw-desktopArticleTarget-loading-overlay{position:absolute;left:0;right:0;z-index:1;margin-top:-0.5em}.ve-init-mw-desktopArticleTarget-progress{height:1em;overflow:hidden;margin:0 25%}.ve-init-mw-desktopArticleTarget-progress-bar{height:1em;width:0} .mw-editsection{white-space:nowrap; unicode-bidi:-moz-isolate;unicode-bidi:-webkit-isolate;unicode-bidi:isolate}.mw-editsection-divider{color:#54595d} .ve-init-mw-desktopArticleTarget-progress{height:0.75em;border:1px solid #36c;background:#fff;border-radius:2px;box-shadow:0 0.1em 0 0 rgba( 0,0,0,0.15 )}.ve-init-mw-desktopArticleTarget-progress-bar{height:0.75em;background:#36c}
@media print{#centralNotice{display:none}}.cn-closeButton{display:inline-block;zoom:1;background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAATCAYAAAByUDbMAAACeklEQVR4Aa1UM3jkcRBN6qS//tTFttPHqmI359VZ5dm2L1zFtr02YlRx5sX2ft/7ed7O/w1M5ufnt8NZQjCBQXhG+IYZe5zjfju7xcHc3NzEzMwM6xOEqNnZ2ZeVlZW827dv1ycmJnbGx8d3Yr5582Z9eXk5D/d4h/empqYm+K0nw3yKcF4sFmdzOJzGgIAAhb29vc7Ozk6/Atrr/fz8lCwWq6m3tzcb72G3nmzFo/NNTU354eHhIltbW72Tk5M2IyND9P79+8ZPnz7VvXnzpoHBYPS4uLhobGxsDMHBwaLa2tp82MF+PVmUUqnMioiI6LOysjLQLCcPS2ZmZn7Ozc39oPtFYG80GgWpqakSS0tLY1hYmEgikWTBfoXsLD16BT3gUWhoqEKtVheREZ+Qu0IEjI+PZ2k0GqFer+cnJSWJra2tDWw2u2FqauoVeEAW3NzcnBcYGCh3dHTUtba2ltNjLvRJSEiQEQEPRENDQzkMBqPXwsKiXyqVFsFDNzc3LWmoqKmp4YIHZIyHDx9WOzg46GJiYmTk5e/h4eHstLQ0CX2ykXST4JPJ8y7sSVM5/QGMf9y4caMHf3r//v1a8IDsGRm04/D58+dtpNFPPNRqtflXrlzpI8G15IEGc2xsrFSlUglwD+Tk5NRBmuTk5A7wgOxbXFxcF8iysrIa1mskEolKvL29Ne7u7mpXV1dNaWlp9fr7X79+VYMMeQieY/dsv5p1r2g2Nja2vWZ7RXNiYuIA0dwlzwYGBjbkGXmURXeLeUa1ul2ebV8BEH+7CiAiASTYvgJ2qc3MzMzF2vz8+XPd27dvG5hMZg+CsV1tHmfXOP5+dqyddgHOI7v1srTdcwAAAABJRU5ErkJggg==);background:url(/w/extensions/CentralNotice/resources/subscribing/CloseWindow19x19.png?7596b)!ie;width:19px;height:19px;text-indent:19px;white-space:nowrap;overflow:hidden}</style><style>
table.jquery-tablesorter th.headerSort{background-image:url(/w/resources/src/jquery/images/sort_both.png?8b01b);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2221%22 height=%229%22 viewBox=%220 0 21 9%22%3E%0A%09%3Cpath d=%22M14.5 5l-4 4-4-4zM14.5 4l-4-4-4 4z%22/%3E%0A%3C/svg%3E%0A");cursor:pointer;background-repeat:no-repeat;background-position:center right;padding-right:21px}table.jquery-tablesorter th.headerSortUp{background-image:url(/w/resources/src/jquery/images/sort_up.png?76242);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2221%22 height=%224%22 viewBox=%220 0 21 4%22%3E%0A%09%3Cpath d=%22M6.5 4l4-4 4 4z%22/%3E%0A%3C/svg%3E%0A")}table.jquery-tablesorter th.headerSortDown{background-image:url(/w/resources/src/jquery/images/sort_down.png?3f399);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2221%22 height=%224%22 viewBox=%220 0 21 4%22%3E%0A%09%3Cpath d=%22M14.5 0l-4 4-4-4z%22/%3E%0A%3C/svg%3E%0A")}</style><style>
.mw-ui-icon-popups-settings:before{background-image:url(/w/load.php?modules=ext.popups.images&image=popups-settings&format=rasterized&lang=es&skin=vector&version=0289bl1);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22utf-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 24 24%22%3E%0A %3Cpath fill=%22%2354595d%22 d=%22M20 14.5v-2.9l-1.8-.3c-.1-.4-.3-.8-.6-1.4l1.1-1.5-2.1-2.1-1.5 1.1c-.5-.3-1-.5-1.4-.6L13.5 5h-2.9l-.3 1.8c-.5.1-.9.3-1.4.6L7.4 6.3 5.3 8.4l1 1.5c-.3.5-.4.9-.6 1.4l-1.7.2v2.9l1.8.3c.1.5.3.9.6 1.4l-1 1.5 2.1 2.1 1.5-1c.4.2.9.4 1.4.6l.3 1.8h3l.3-1.8c.5-.1.9-.3 1.4-.6l1.5 1.1 2.1-2.1-1.1-1.5c.3-.5.5-1 .6-1.4l1.5-.3zM12 16c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3z%22/%3E%0A%3C/svg%3E%0A")}.mw-ui-icon-popups-close:before{background-image:url(/w/load.php?modules=ext.popups.images&image=popups-close&format=rasterized&lang=es&skin=vector&version=0289bl1);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%0A%09%3Cpath d=%22M3.636 2.222l14.142 14.142-1.414 1.414L2.222 3.636z%22/%3E%0A%09%3Cpath d=%22M17.778 3.636L3.636 17.778l-1.414-1.414L16.364 2.222z%22/%3E%0A%3C/svg%3E%0A")}
.uls-menu{border-radius:2px; font-size:medium}.uls-search,.uls-language-settings-close-block{border-top-right-radius:2px;border-top-left-radius:2px}.uls-language-list{border-bottom-right-radius:2px;border-bottom-left-radius:2px}.uls-menu.callout:before,.uls-menu.callout:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.uls-menu.callout.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.uls-menu.callout.selector-right:after{ border-left:10px solid #f8f9fa; right:-10px}.uls-menu.callout.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.uls-menu.callout.selector-left:after{ border-right:10px solid #f8f9fa; left:-10px}.uls-ui-languages button{margin:5px 15px 5px 0;white-space:nowrap;overflow:hidden}.uls-search-wrapper-wrapper{position:relative;padding-left:40px;margin-top:5px;margin-bottom:5px}.uls-icon-back{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.png?90e9b) no-repeat scroll center center;background-image:-webkit-linear-gradient(transparent,transparent),url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.svg?e226b);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2224%22 height=%2224%22 viewBox=%220 0 24 24%22%3E%0A%09%3Cpath fill=%22%2354595d%22 d=%22M7 13.1l8.9 8.9c.8-.8.8-2 0-2.8l-6.1-6.1 6-6.1c.8-.8.8-2 0-2.8L7 13.1z%22/%3E%0A%3C/svg%3E%0A");background-size:28px;background-position:center center;height:32px;width:40px;display:block;position:absolute;left:0;border-right:1px solid #c8ccd1;opacity:0.8}.uls-icon-back:hover{opacity:1;cursor:pointer}  .skin-vector .uls-menu{border-color:#c8ccd1;-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);font-size:0.875em}.skin-vector .uls-search{border-bottom-color:#c8ccd1}.skin-vector .uls-filtersuggestion{color:#72777d}.skin-vector .uls-lcd-region-title{color:#54595d}
.suggestions{overflow:hidden;position:absolute;top:0;left:0;width:0;border:0;z-index:1099;padding:0;margin:-1px 0 0 0}.suggestions-special{position:relative;background-color:#fff;cursor:pointer;border:1px solid #a2a9b1;margin:0;margin-top:-2px;display:none;padding:0.25em 0.25em;line-height:1.25em}.suggestions-results{background-color:#fff;cursor:pointer;border:1px solid #a2a9b1;padding:0;margin:0}.suggestions-result{color:#000;margin:0;line-height:1.5em;padding:0.01em 0.25em;text-align:left; overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.suggestions-result-current{background-color:#2a4b8d;color:#fff}.suggestions-special .special-label{color:#72777d;text-align:left}.suggestions-special .special-query{color:#000;font-style:italic;text-align:left}.suggestions-special .special-hover{background-color:#c8ccd1}.suggestions-result-current .special-label,.suggestions-result-current .special-query{color:#fff}.highlight{font-weight:bold}
.mw-ui-button{font-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.546875em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px solid #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-ui-button:visited{color:#222222}.mw-ui-button:hover{background-color:#ffffff;color:#444444;border-color:#a2a9b1}.mw-ui-button:focus{background-color:#ffffff;color:#222222;border-color:#3366cc;box-shadow:inset 0 0 0 1px #3366cc,inset 0 0 0 2px #ffffff}.mw-ui-button:active,.mw-ui-button.is-on,.mw-ui-button.mw-ui-checked{background-color:#d9d9d9;color:#000000;border-color:#72777d;box-shadow:none}.mw-ui-button:disabled{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1}.mw-ui-button:disabled:hover,.mw-ui-button:disabled:active{background-color:#c8ccd1;color:#fff;box-shadow:none;border-color:#c8ccd1}.mw-ui-button:focus{outline-width:0}.mw-ui-button:focus::-moz-focus-inner{border-color:transparent;padding:0}.mw-ui-button:not( :disabled ){-webkit-transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms;-moz-transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms;transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms}.mw-ui-button:disabled{text-shadow:none;cursor:default}.mw-ui-button.mw-ui-big{font-size:1.3em}.mw-ui-button.mw-ui-block{display:block;width:100%;margin-left:auto;margin-right:auto}.mw-ui-button.mw-ui-progressive{background-color:#3366cc;color:#fff;border:1px solid #3366cc}.mw-ui-button.mw-ui-progressive:hover{background-color:#447ff5;border-color:#447ff5}.mw-ui-button.mw-ui-progressive:focus{box-shadow:inset 0 0 0 1px #3366cc,inset 0 0 0 2px #ffffff}.mw-ui-button.mw-ui-progressive:active,.mw-ui-button.mw-ui-progressive.is-on,.mw-ui-button.mw-ui-progressive.mw-ui-checked{background-color:#2a4b8d;border-color:#2a4b8d;box-shadow:none}.mw-ui-button.mw-ui-progressive:disabled{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1}.mw-ui-button.mw-ui-progressive:disabled:hover,.mw-ui-button.mw-ui-progressive:disabled:active,.mw-ui-button.mw-ui-progressive:disabled.mw-ui-checked{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1;box-shadow:none}.mw-ui-button.mw-ui-progressive.mw-ui-quiet{color:#222222}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:hover{background-color:transparent;color:#447ff5}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:active,.mw-ui-button.mw-ui-progressive.mw-ui-quiet.mw-ui-checked{color:#2a4b8d}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:focus{background-color:transparent;color:#3366cc}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:disabled{color:#c8ccd1}.mw-ui-button.mw-ui-destructive{background-color:#dd3333;color:#fff;border:1px solid #dd3333}.mw-ui-button.mw-ui-destructive:hover{background-color:#ff4242;border-color:#ff4242}.mw-ui-button.mw-ui-destructive:focus{box-shadow:inset 0 0 0 1px #dd3333,inset 0 0 0 2px #ffffff}.mw-ui-button.mw-ui-destructive:active,.mw-ui-button.mw-ui-destructive.is-on,.mw-ui-button.mw-ui-destructive.mw-ui-checked{background-color:#b32424;border-color:#b32424;box-shadow:none}.mw-ui-button.mw-ui-destructive:disabled{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1}.mw-ui-button.mw-ui-destructive:disabled:hover,.mw-ui-button.mw-ui-destructive:disabled:active,.mw-ui-button.mw-ui-destructive:disabled.mw-ui-checked{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1;box-shadow:none}.mw-ui-button.mw-ui-destructive.mw-ui-quiet{color:#222222}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:hover{background-color:transparent;color:#ff4242}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:active,.mw-ui-button.mw-ui-destructive.mw-ui-quiet.mw-ui-checked{color:#b32424}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:focus{background-color:transparent;color:#dd3333}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:disabled{color:#c8ccd1}.mw-ui-button.mw-ui-quiet{background:transparent;border:0;text-shadow:none;color:#222222}.mw-ui-button.mw-ui-quiet:hover{background-color:transparent;color:#444444}.mw-ui-button.mw-ui-quiet:active,.mw-ui-button.mw-ui-quiet.mw-ui-checked{color:#000000}.mw-ui-button.mw-ui-quiet:focus{background-color:transparent;color:#222222}.mw-ui-button.mw-ui-quiet:disabled{color:#c8ccd1}.mw-ui-button.mw-ui-quiet:hover,.mw-ui-button.mw-ui-quiet:focus{box-shadow:none}.mw-ui-button.mw-ui-quiet:active,.mw-ui-button.mw-ui-quiet:disabled{background:transparent}input.mw-ui-button::-moz-focus-inner,button.mw-ui-button::-moz-focus-inner{margin-top:-1px;margin-bottom:-1px}a.mw-ui-button{text-decoration:none}a.mw-ui-button:hover,a.mw-ui-button:focus{text-decoration:none}.mw-ui-button-group > *{min-width:48px;border-radius:0;float:left}.mw-ui-button-group > *:first-child{border-top-left-radius:2px;border-bottom-left-radius:2px}.mw-ui-button-group > *:not( :first-child ){border-left:0}.mw-ui-button-group > *:last-child{border-top-right-radius:2px;border-bottom-right-radius:2px}.mw-ui-button-group .is-on .button{cursor:default}
.mw-ui-icon{position:relative;line-height:1.5em;min-height:1.5em;min-width:1.5em}.mw-ui-icon.mw-ui-icon-element{text-indent:-999px;overflow:hidden;width:3.5em;min-width:3.5em;max-width:3.5em}.mw-ui-icon.mw-ui-icon-element:before{left:0;right:0;position:absolute;margin:0 1em}.mw-ui-icon.mw-ui-icon-element.mw-ui-icon-large{width:4.625em;min-width:4.625em;max-width:4.625em;line-height:4.625em;min-height:4.625em}.mw-ui-icon.mw-ui-icon-element.mw-ui-icon-large:before{min-height:4.625em}.mw-ui-icon.mw-ui-icon-before:before,.mw-ui-icon.mw-ui-icon-element:before{background-position:50% 50%;background-repeat:no-repeat;background-size:100% auto;float:left;display:block;min-height:1.5em;content:''}.mw-ui-icon.mw-ui-icon-before:before{position:relative;width:1.5em;margin-right:1em}.mw-ui-icon.mw-ui-icon-small:before{background-size:66.67% auto}</style><style>
#uls-settings-block{background-color:#f8f9fa;border-top:1px solid #c8ccd1;padding-left:10px;line-height:1.2em;border-radius:0 0 2px 2px}#uls-settings-block div.display-settings-block,#uls-settings-block div.input-settings-block{display:inline-block;margin:8px 15px;color:#54595d}#uls-settings-block div.display-settings-block:hover,#uls-settings-block div.input-settings-block:hover{color:#222}
.suggestions a.mw-searchSuggest-link,.suggestions a.mw-searchSuggest-link:hover,.suggestions a.mw-searchSuggest-link:active,.suggestions a.mw-searchSuggest-link:focus{color:#000;text-decoration:none}.suggestions-result-current a.mw-searchSuggest-link,.suggestions-result-current a.mw-searchSuggest-link:hover,.suggestions-result-current a.mw-searchSuggest-link:active,.suggestions-result-current a.mw-searchSuggest-link:focus{color:#fff}.suggestions a.mw-searchSuggest-link .special-query{ overflow:hidden;text-overflow:ellipsis;white-space:nowrap}
#p-lang .body ul .uls-trigger,#p-lang .pBody ul .uls-trigger{background-image:none;padding:0} .mw-interlanguage-selector,.mw-interlanguage-selector:active{cursor:pointer;padding:4px 6px 4px 25px;font-size:13px;font-weight:normal;background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/compact-links-trigger.png?b0c8e);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2218%22 height=%2218%22 viewBox=%220 0 24 24%22%3E%0A%09%3Cpath fill=%22%2372777d%22 d=%22M13 19l.8-3h5.3l.9 3h2.2l-4.2-13h-3l-4.2 13h2.2zm3.5-11l2 6h-4l2-6zM5 4l.938 1.906h-4.938v2.094h1.594c.6 1.8 1.406 3.206 2.406 4.406-1.1.7-4.313 1.781-4.313 1.781l1.313 1.813s3.487-1.387 4.688-2.188c1 .7 2.319 1.188 3.719 1.688l.594-2c-1-.3-1.988-.688-2.688-1.188 1.1-1.1 1.9-2.506 2.5-4.406h2.188l.5-2h-5.563l-.938-1.906h-2zm-.188 4h3.781c-.4 1.3-.906 2-1.906 3-1.1-1-1.475-1.7-1.875-3z%22/%3E%0A%3C/svg%3E%0A");background-size:18px;background-repeat:no-repeat;background-position:left 4px center;margin:4px 0;text-align:left}.mw-interlanguage-selector:active,.mw-interlanguage-selector.selector-open{background-color:#c8ccd1;color:#54595d}.interlanguage-uls-menu:before,.interlanguage-uls-menu:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.interlanguage-uls-menu.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.interlanguage-uls-menu.selector-right:after{ border-left:10px solid #f8f9fa; right:-10px}.interlanguage-uls-menu.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.interlanguage-uls-menu.selector-left:after{ border-right:10px solid #f8f9fa; left:-10px}
.mw-mmv-overlay{position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000;background-color:#000}body.mw-mmv-lightbox-open{overflow-y:auto;  }body.mw-mmv-lightbox-open #mw-page-base,body.mw-mmv-lightbox-open #mw-head-base,body.mw-mmv-lightbox-open #mw-navigation,body.mw-mmv-lightbox-open #content,body.mw-mmv-lightbox-open #footer,body.mw-mmv-lightbox-open #globalWrapper{ display:none}body.mw-mmv-lightbox-open > *{ display:none}body.mw-mmv-lightbox-open > .mw-mmv-overlay,body.mw-mmv-lightbox-open > .mw-mmv-wrapper{display:block}.mw-mmv-filepage-buttons{margin-top:5px}.mw-mmv-filepage-buttons .mw-mmv-view-expanded,.mw-mmv-filepage-buttons .mw-mmv-view-config{display:block;line-height:inherit}.mw-mmv-filepage-buttons .mw-mmv-view-expanded.mw-ui-icon:before{background-image:url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22 standalone=%22no%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E%0A %3Cg fill=%22%2372777d%22%3E%0A %3Cpath d=%22M851.2 71.6L690.7 232.1l-40.1-40.3-9.6 164.8 164.8-9.3-40.3-40.4L926 146.4l58.5 58.5L997.6 0 792.7 13.1%22/%3E%0A %3Cpath d=%22M769.6 89.3H611.9l70.9 70.8 7.9 7.5m-47.1 234.6l-51.2 3 3-51.2 9.4-164.4 5.8-100.3H26.4V768h883.1V387l-100.9 5.8-165 9.4zM813.9 678H113.6l207.2-270.2 31.5-12.9L548 599.8l105.9-63.2 159.8 140.8.2.6zm95.6-291.9V228l-79.1 78.9 7.8 7.9%22/%3E%0A %3C/g%3E%0A%3C/svg%3E%0A")}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before{background-image:url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22 standalone=%22no%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E%0A %3Cpath d=%22M897 454.6V313.4L810.4 299c-6.4-23.3-16-45.7-27.3-65.8l50.5-71.4-99.4-100.2-71.4 50.5c-20.9-11.2-42.5-20.9-65.8-27.3L582.6-1H441.4L427 85.6c-23.3 6.4-45.7 16-65.8 27.3l-71.4-50.5-100.3 99.5 50.5 71.4c-11.2 20.9-20.9 42.5-27.3 66.6L127 313.4v141.2l85.8 14.4c6.4 23.3 16 45.7 27.3 66.6L189.6 607l99.5 99.5 71.4-50.5c20.9 11.2 42.5 20.9 66.6 27.3l14.4 85.8h141.2l14.4-86.6c23.3-6.4 45.7-16 65.8-27.3l71.4 50.5 99.5-99.5-50.5-71.4c11.2-20.9 20.9-42.5 27.3-66.6l86.4-13.6zm-385 77c-81.8 0-147.6-66.6-147.6-147.6 0-81.8 66.6-147.6 147.6-147.6S659.6 302.2 659.6 384 593.8 531.6 512 531.6z%22 fill=%22%2372777d%22/%3E%0A%3C/svg%3E%0A");opacity:0.75}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before:hover{opacity:1}
#mwe-popups-svg{position:absolute;top:-1000px}.mwe-popups-settings-icon{border-radius:2px;font-size:16px; margin-right:-0.75em}.mwe-popups-settings-icon:hover{background-color:#eaecf0}.mwe-popups-settings-icon:active{background-color:#c8ccd1}.mwe-popups-sade-face-icon{display:block;width:37px;height:27px;margin:16px 16px 0;background-position:center center;background-repeat:no-repeat;background-image:url(/w/extensions/Popups/resources/ext.popups/images/sad-face.png?3984d);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2237%22 height=%2227%22 viewBox=%220 0 37 27%22%3E%0A%09%3Ctitle%3Esad face%3C/title%3E%0A%09%3Cpath fill=%22%23c8ccd1%22 fill-rule=%22evenodd%22 d=%22M5.475.7v20.075L0 26.25h31.025c3.102 0 5.475-2.372 5.475-5.475V.7H5.475zm20.44 4.562c1.277 0 2.19 1.095 2.19 2.19 0 1.096-.913 2.373-2.19 2.373-1.278 0-2.19-1.095-2.19-2.19s1.095-2.373 2.19-2.373zm-9.855 0c1.277 0 2.19 1.095 2.19 2.19 0 1.096-1.095 2.373-2.19 2.373s-2.19-1.095-2.19-2.19.913-2.373 2.19-2.373zm4.928 8.213c-7.153 0-8.415 7.012-8.415 7.012s2.805-1.403 8.415-1.403c5.61 0 8.414 1.403 8.414 1.403S28 13.475 20.988 13.475z%22/%3E%0A%3C/svg%3E%0A")}.mwe-popups{background:#fff;position:absolute;z-index:110;-webkit-box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px #a2a9b1;box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px #a2a9b1;padding:0;display:none;font-size:14px;line-height:20px;min-width:300px;border-radius:2px; }.mwe-popups .mwe-popups-container{color:#222222;margin-top:-9px;padding-top:9px;text-decoration:none}.mwe-popups .mwe-popups-container footer{padding:16px;margin:0;font-size:10px;position:absolute;bottom:0; left:0}.mwe-popups .mwe-popups-container footer .mwe-popups-settings-icon{float:right}.mwe-popups .mwe-popups-extract{margin:16px;display:block;color:#222222;text-decoration:none;position:relative;   }.mwe-popups .mwe-popups-extract:hover{text-decoration:none}.mwe-popups .mwe-popups-extract:after{content:' ';position:absolute;bottom:0;width:25%;height:20px;background-color:transparent}.mwe-popups .mwe-popups-extract[dir='ltr']:after{ right:0; background-image:-webkit-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:-moz-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:-o-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract[dir='rtl']:after{ left:0; background-image:-webkit-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:-moz-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:-o-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract p{margin:0}.mwe-popups .mwe-popups-extract ul,.mwe-popups .mwe-popups-extract ol,.mwe-popups .mwe-popups-extract li,.mwe-popups .mwe-popups-extract dl,.mwe-popups .mwe-popups-extract dd,.mwe-popups .mwe-popups-extract dt{margin-top:0;margin-bottom:0}.mwe-popups svg{overflow:hidden}.mwe-popups.mwe-popups-is-tall{width:450px}.mwe-popups.mwe-popups-is-tall > div > a > svg{vertical-align:middle}.mwe-popups.mwe-popups-is-tall .mwe-popups-extract{width:215px;height:180px;overflow:hidden; float:left}.mwe-popups.mwe-popups-is-tall footer{width:215px}.mwe-popups.mwe-popups-is-not-tall{width:320px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-extract{max-height:140px;overflow:hidden;margin-bottom:47px;padding-bottom:0}.mwe-popups.mwe-popups-is-not-tall footer{width:290px}.mwe-popups.mwe-popups-is-empty .mwe-popups-extract{padding-top:4px;margin-bottom:60px}.mwe-popups.mwe-popups-is-empty .mwe-popups-read-link{font-weight:bold;font-size:12px}.mwe-popups.mwe-popups-is-empty .mwe-popups-extract:hover + footer .mwe-popups-read-link{text-decoration:underline}.mwe-popups.mwe-popups-no-image-tri:after{content:'';position:absolute;border:11px solid transparent;border-top:0;border-bottom:11px solid #ffffff;top:-7px; left:7px}.mwe-popups.mwe-popups-no-image-tri:before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid #a2a9b1;top:-8px; left:10px}.mwe-popups.flipped_x.mwe-popups-no-image-tri:after{ left:auto; right:7px}.mwe-popups.flipped_x.mwe-popups-no-image-tri:before{ left:auto; right:10px}.mwe-popups.mwe-popups-image-tri:before{z-index:111;content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px; left:9px}.mwe-popups.mwe-popups-image-tri:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px; left:6px;z-index:112}.mwe-popups.mwe-popups-image-tri.flipped_x:before{z-index:111;content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px; left:273px}.mwe-popups.mwe-popups-image-tri.flipped_x:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px; left:269px;z-index:112}.mwe-popups.mwe-popups-image-tri .mwe-popups-extract{padding-top:32px;margin-top:190px}.mwe-popups.mwe-popups-image-tri > div > a > svg{margin-top:-8px;position:absolute;z-index:113; left:0}.mwe-popups.flipped_x.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped_x.mwe-popups-is-tall:before{z-index:111;content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px; left:420px}.mwe-popups.flipped_x.mwe-popups-is-tall > div > a > svg{margin:0;margin-top:-8px;margin-bottom:-7px;position:absolute;z-index:113; right:0}.mwe-popups.flipped_x_y:before{z-index:111;content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px; left:272px}.mwe-popups.flipped_x_y:after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px; left:269px;z-index:112}.mwe-popups.flipped_x_y.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped_x_y.mwe-popups-is-tall:after{z-index:112;content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px; left:417px}.mwe-popups.flipped_x_y.mwe-popups-is-tall:before{z-index:111;content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px; left:420px}.mwe-popups.flipped_x_y.mwe-popups-is-tall > div > a > svg{position:absolute;z-index:113;margin:0;margin-bottom:-9px; right:0}.mwe-popups.flipped_y:after{content:'';position:absolute;border:11px solid transparent;border-bottom:0;border-top:11px solid #ffffff;bottom:-7px; left:7px}.mwe-popups.flipped_y:before{content:'';position:absolute;border:8px solid transparent;border-bottom:0;border-top:8px solid #a2a9b1;bottom:-8px; left:10px} @-webkit-keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-moz-keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-webkit-keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-moz-keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-webkit-keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@-moz-keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@-webkit-keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}@-moz-keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}@keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}.mwe-popups-fade-in-up{-webkit-animation:mwe-popups-fade-in-up 0.2s ease forwards;-moz-animation:mwe-popups-fade-in-up 0.2s ease forwards;animation:mwe-popups-fade-in-up 0.2s ease forwards}.mwe-popups-fade-in-down{-webkit-animation:mwe-popups-fade-in-down 0.2s ease forwards;-moz-animation:mwe-popups-fade-in-down 0.2s ease forwards;animation:mwe-popups-fade-in-down 0.2s ease forwards}.mwe-popups-fade-out-down{-webkit-animation:mwe-popups-fade-out-down 0.2s ease forwards;-moz-animation:mwe-popups-fade-out-down 0.2s ease forwards;animation:mwe-popups-fade-out-down 0.2s ease forwards}.mwe-popups-fade-out-up{-webkit-animation:mwe-popups-fade-out-up 0.2s ease forwards;-moz-animation:mwe-popups-fade-out-up 0.2s ease forwards;animation:mwe-popups-fade-out-up 0.2s ease forwards}  #mwe-popups-settings{position:fixed;z-index:1000;background:#fff;width:420px;border:1px solid #a2a9b1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);border-radius:2px}#mwe-popups-settings header{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;border-bottom:1px solid #c8ccd1;position:relative;display:table;width:100%;padding:5px 7px 5px 0}#mwe-popups-settings header > div{display:table-cell;width:3.5em;vertical-align:middle;cursor:pointer}#mwe-popups-settings header h1{border:0;width:100%;font-family:sans-serif;font-size:18px;font-weight:bold;text-align:center}#mwe-popups-settings .mwe-ui-icon-popups-close{opacity:0.87;-webkit-transition:opacity 100ms;-moz-transition:opacity 100ms;transition:opacity 100ms}#mwe-popups-settings .mwe-ui-icon-popups-close:hover{opacity:0.73}#mwe-popups-settings .mwe-ui-icon-popups-close:active{opacity:1}#mwe-popups-settings main{display:block;width:350px;padding:32px 0 24px;margin:0 auto}#mwe-popups-settings main p{color:#54595d;font-size:17px;margin:16px 0 0}#mwe-popups-settings main p:first-child{margin-top:0}#mwe-popups-settings main form img,#mwe-popups-settings main form input,#mwe-popups-settings main form label{vertical-align:top}#mwe-popups-settings main form img{margin-right:60px}#mwe-popups-settings main form input{display:inline-block;margin:0 10px 0 0;padding:0}#mwe-popups-settings main form label{font-size:13px;display:inline-block;line-height:16px;width:300px}#mwe-popups-settings main form label > span{color:#000;font-size:18px;font-weight:bold;display:block;margin-bottom:5px;line-height:18px}.mwe-popups-settings-help{background-image:url(/w/extensions/Popups/resources/ext.popups/images/footer-ltr.png?3533c);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3C%3Fxml version=%221.0%22 encoding=%22UTF-8%22%3F%3E%0A%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%22230%22 height=%22179%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 viewBox=%220 0 230 179%22%3E%0A%09%3Cdefs%3E%0A%09%09%3Crect id=%22a%22 width=%22201%22 height=%2213%22 rx=%222%22/%3E%0A%09%09%3Crect id=%22b%22 width=%22201%22 height=%22169%22 y=%2210%22 rx=%222%22/%3E%0A%09%09%3Crect id=%22c%22 width=%2230%22 height=%222%22 x=%22135%22 y=%22158%22 rx=%221%22/%3E%0A%09%3C/defs%3E%0A%09%3Cg fill=%22none%22 fill-rule=%22evenodd%22%3E%0A%09%09%3Cg transform=%22matrix%281 0 0 -1 0 13%29%22%3E%0A%09%09%09%3Cuse fill=%22%23f8f9fa%22 xlink:href=%22%23a%22/%3E%0A%09%09%09%3Crect width=%22199%22 height=%2211%22 x=%221%22 y=%221%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E%0A%09%09%3C/g%3E%0A%09%09%3Cuse fill=%22%23fff%22 xlink:href=%22%23b%22/%3E%0A%09%09%3Crect width=%22199%22 height=%22167%22 x=%221%22 y=%2211%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E%0A%09%09%3Cg opacity=%22.4%22 transform=%22translate%2867 35%29%22%3E%0A%09%09%09%3Crect width=%2273%22 height=%222%22 y=%227%22 fill=%22%23c8ccd1%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2281%22 height=%222%22 y=%2231%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2232%22 height=%222%22 y=%2285%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2273%22 height=%222%22 x=%2235%22 y=%2285%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2217%22 height=%222%22 y=%2245%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2217%22 height=%222%22 x=%2291%22 y=%2245%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2268%22 height=%222%22 x=%2220%22 y=%2245%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2217%22 height=%222%22 y=%2278%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2237%22 height=%222%22 x=%2272%22 y=%2278%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2249%22 height=%222%22 x=%2220%22 y=%2278%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2224%22 height=%222%22 x=%2284%22 y=%2231%22 fill=%22%2372777d%22 rx=%221%22 transform=%22matrix%28-1 0 0 1 192 0%29%22/%3E%0A%09%09%09%3Crect width=%2281%22 height=%222%22 y=%2266%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2214%22 height=%222%22 x=%2254%22 y=%2224%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2237%22 height=%222%22 x=%2271%22 y=%2224%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2251%22 height=%222%22 y=%2224%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%22108%22 height=%222%22 y=%2259%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%22108%22 height=%222%22 y=%2252%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%22108%22 height=%222%22 y=%2292%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%22108%22 height=%222%22 y=%2238%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%09%3Crect width=%2251%22 height=%222%22 fill=%22%2372777d%22 rx=%221%22/%3E%0A%09%09%3C/g%3E%0A%09%09%3Crect width=%2230%22 height=%222%22 x=%2267%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E%0A%09%09%3Crect width=%2230%22 height=%222%22 x=%2299%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E%0A%09%09%3Cuse fill=%22%2336c%22 xlink:href=%22%23c%22/%3E%0A%09%09%3Crect width=%2233%22 height=%225%22 x=%22133.5%22 y=%22156.5%22 stroke=%22%23ffc057%22 stroke-opacity=%22.447%22 stroke-width=%223%22 rx=%222.5%22/%3E%0A%09%09%3Ccircle cx=%2234%22 cy=%2249%22 r=%2219%22 fill=%22%23eaecf0%22/%3E%0A%09%09%3Cg fill=%22%23a2a9b1%22 transform=%22translate%285 5%29%22%3E%0A%09%09%09%3Ccircle cx=%221.5%22 cy=%221.5%22 r=%221.5%22/%3E%0A%09%09%09%3Ccircle cx=%226%22 cy=%221.5%22 r=%221.5%22/%3E%0A%09%09%09%3Ccircle cx=%2210.5%22 cy=%221.5%22 r=%221.5%22/%3E%0A%09%09%3C/g%3E%0A%09%09%3Cpath stroke=%22%23ff00af%22 d=%22M174.5 159.5h54.01%22 stroke-linecap=%22square%22/%3E%0A%09%3C/g%3E%0A%3C/svg%3E%0A");background-position:top left;background-repeat:no-repeat;background-size:180px 140px;font-size:13px;font-weight:800;height:140px;margin:40px;position:relative}.mwe-popups-settings-help p{left:180px;bottom:20px;position:absolute}.mwe-popups-overlay{background-color:rgba(255,255,255,0.9);z-index:999;position:fixed;height:100%;width:100%;top:0;bottom:0;left:0;right:0}#mwe-popups-settings{font-size:0.875em}</style><meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="./Entropía (información)_files/load(2).php">
<link rel="stylesheet" href="./Entropía (información)_files/load(3).php">
<meta name="generator" content="MediaWiki 1.31.0-wmf.11">
<meta name="referrer" content="origin-when-cross-origin">
<link rel="alternate" href="android-app://org.wikipedia/http/es.m.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)">
<link rel="alternate" type="application/x-wiki" title="Editar" href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit">
<link rel="edit" title="Editar" href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit">
<link rel="apple-touch-icon" href="https://es.wikipedia.org/static/apple-touch/wikipedia.png">
<link rel="shortcut icon" href="https://es.wikipedia.org/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="https://es.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (es)">
<link rel="EditURI" type="application/rsd+xml" href="https://es.wikipedia.org/w/api.php?action=rsd">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/">
<link rel="canonical" href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)">
<link rel="dns-prefetch" href="https://login.wikimedia.org/">
<link rel="dns-prefetch" href="https://meta.wikimedia.org/">
<!--[if lt IE 9]><script src="/w/load.php?debug=false&amp;lang=es&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1"></script><![endif]-->
<script src="./Entropía (información)_files/load(4).php"></script><style type="text/css" nonce="3B816D273C619344B8B0430D2D2C7E7D">#AD_Top,#AD_banner,#AdColumn,#AdContainer,#AdHeader,#AdImage,#Adcode,#AdvertiseFrame,#BottomAdContainer,#BottomAds,#ContentAd,#PreRollAd,#RightAdBlock,#TopAd,#WNAd41,#ad-area,#ad-background,#ad-bg,#ad-bottom,#ad-container,#ad-header,#ad-header-728x90,#ad-leaderboard,#ad-main,#ad-panel,#ad-right,#ad-rotator,#ad-text,#ad-top,#ad-top-banner-placeholder,#ad-top-wrapper,#ad-unit,#ad-wrapper,#ad468,#ad728,#ad728x90,#adBanner,#adBelt,#adComponentWrapper,#adDiv,#adFrame,#adGallery,#adHeader,#adHolder,#adLayer,#adLeader,#adPosition0,#adText,#ad_1,#ad_2,#ad_3,#ad_4,#ad_5,#ad_728_90,#ad_area,#ad_banner,#ad_center,#ad_content,#ad_header,#ad_leaderboard,#ad_main,#ad_overlay,#ad_space,#ad_square,#ad_table,#ad_topslot,#ad_unit,#ad_wrap,#ad_wrapper,#adaptv_ad_player_div,#adbackground,#adbanner,#adbar,#adblock,#adboard,#adbody,#adbox,#adcode,#adcontainer,#adcontainer1,#adcontent,#adhead,#adheader,#adimg1,#adlayer,#adnews,#adposition3,#adright,#ads-col,#ads-wrapper,#ads1,#adsHeader,#adsIframe,#ads_bottom,#ads_right,#ads_top,#ads_wrapper,#adsdiv,#adsense,#adsense_block,#adsense_inline,#adsensewide,#adspace,#adspace_top,#adspot-300x250-pos-1,#adspot-300x250-pos-2,#adstop,#adtext,#adtop,#adv-masthead,#adv-top,#advert1,#advert2,#advertContainer,#advert_box,#advertise,#advertisement1,#advertisetop,#advertising_wrapper,#adverts,#advtop,#adwrapper,#banner-ad,#bannerAd,#bannerAdWrapper,#banner_topad,#bannerad,#bigAd,#bigad,#body_ad,#bottomAd,#bottomAds,#bottom_ad,#centerads,#cmn_ad_tag_head,#companionAd,#content-header-ad,#contentAd,#content_ads,#content_adv,#contentad,#ctlDisplayAd1_lblAd,#dart-container-728x90,#dfp_ad_Entry_728x90,#dfp_ad_Home_728x90,#divAd,#div_prerollAd_1,#download_ad,#featuread,#featured-ads,#featuredAds,#footer_ad,#footer_ads,#game-ad,#googlead,#gridAdSidebar,#head-ad,#header-ads,#headerAd,#headerAdContainer,#header_ad,#homead,#ka_adRightSkyscraperWide,#leaderAd,#leaderBoardAd,#leaderboard-ad,#leaderboard-advertisement,#leaderboardad,#left-ad,#left_ads,#leftad,#leftads,#logoAd,#logo_ad,#mainAd,#main_ad,#mpu2,#mpu2_container,#mpu_container,#msad,#my-adsFPAD,#myAd,#player_ads,#pre_advertising_wrapper,#prerollAd,#promo-ad,#publicidad,#reklama,#rh-ad,#right_ads,#right_adsense,#search-sponsor,#searchAd,#search_ads,#sideAd,#side_ads,#sidebar-ads,#sidebar_ad,#sidebar_ads,#skybox-ad,#sponsorAdDiv,#sponsorText,#sponsoredwellcontainerbottom,#sponsors-home,#takeover_ad,#text-ads,#theAd,#top-ad,#top-ad-content,#topAd,#topAdSpace,#topAdSpace_div,#topAdvert,#topBannerAd,#top_ad,#top_ads,#topad,#topadvert,#topbannerad,#under_story_ad,#videoAd,#videoads,.ADBAR,.AdBar,.AdBody:not(body),.AdBox,.AdInfo,.AdSidebar,.AdTitle,.AdvertContainer,.HomeAds,.IM_ad_unit,.LazyLoadAd,.RelatedAds,.SponsoredContent,.ad-300x250,.ad-970,.ad-banner,.ad-block,.ad-body,.ad-border,.ad-btn,.ad-button,.ad-cat,.ad-cell,.ad-display,.ad-enabled,.ad-header,.ad-holder,.ad-img,.ad-inner,.ad-item,.ad-leader-top,.ad-leaderboard,.ad-left,.ad-link,.ad-links,.ad-loaded,.ad-panel,.ad-placement,.ad-rail,.ad-right,.ad-row,.ad-scroll,.ad-section,.ad-served,.ad-sidebar,.ad-source,.ad-square,.ad-stack,.ad-text,.ad-top,.ad-unit,.ad-unit-300-wrapper,.ad-vertical-container,.ad-wide,.ad-wrap,.ad-wrapper,.ad300,.ad468,.ad728,.ad90,.adBar,.adBlock,.adBottomBoard,.adBox,.adChoicesLogo,.adContent,.adDiv,.adElement,.adFrame,.adFrameCnt,.adHead,.adHeader,.adHeaderblack,.adHeadline,.adHolder,.adHoldert,.adImg,.adItem,.adLink,.adMessage,.adMiddle,.adMod,.adModule,.adOverlay,.adPanel,.adPod,.adResult,.adRight,.adRotator,.adSpace,.adSpot,.adText,.adTitle,.adTopHome,.adWidget,.adWrap,.ad_1,.ad_160,.ad_160x600,.ad_2,.ad_3,.ad_728x90,.ad_960,.ad_Right,.ad_block,.ad_body,.ad_bottom,.ad_container,.ad_description,.ad_global_header,.ad_head_rectangle,.ad_header,.ad_img,.ad_item,.ad_leaderboard,.ad_middle,.ad_outer,.ad_promo,.ad_slug_table,.ad_space,.ad_spot,.ad_text,.ad_title,.ad_trick_header,.ad_trick_left,.ad_wrap,.ad_wrapper,.adarea,.adbanner,.adbar,.adbottom,.adbutton,.adcolumn,.adcont,.addiv,.adframe,.adfree,.adheader,.adholder,.adinfo,.adkit,.adlink,.adlist,.admain,.admiddle,.adright,.adrow1,.adrow2,.ads-1,.ads-2,.ads-3,.ads-300-250,.ads-area,.ads-bg,.ads-col,.ads-header,.ads-holder,.ads-inline,.ads-item,.ads-right,.ads-section,.ads-title,.ads-top,.ads1,.adsBlock,.adsWidget,.ads_catDiv,.ads_div,.ads_top,.ads_wrapper,.adsbottombox,.adsbox,.adsbygoogle,.adscontainer,.adshome,.adside,.adslot,.adslot_blurred,.adspace,.adtable,.adtile,.adtop,.adv300,.adv_300,.adv_txt,.advert-block,.advert-box,.advert-container,.advert-content,.advert-horizontal,.advert-wrapper,.advert2,.advertColumn,.advertContainer,.advertLink,.advertText,.advert_area,.advert_container,.advert_list,.advertbox,.advertisement-1,.advertisement-block,.advertiser,.advertising_banner,.advertising_block,.advertisment,.advertorial,.adverts,.adverttext,.adwords,.afs_ads,.after-post-ad,.article-advert,.article_ad,.b-advert,.b-banner,.banner-ad,.banner-ads,.banner160x600,.banner300,.bannerAd,.banner_728x90,.banner_ad,.bannerad,.block-ad,.block-ec_ads,.block-simpleads,.blog-ads,.bottom-ad,.bottom-ads,.bottom-left-ad,.bottomAds,.bottom_ad_block,.box-ads,.box-radvert,.box-recommend-ad,.box_ads,.box_adv,.boxad,.boxadv,.btn-ad,.can_ad_slug,.category-ad,.change_AdContainer,.chitikaAdBlock,.commerce-inset,.container_ad,.container_row_ad,.contentAd,.contentAds,.content_ads,.content_tagsAdTech,.cp-adsInited,.custom-ad,.desktop-ad,.dfp-ad,.dfp-ad-unit,.dfp-tag-wrapper,.displayAd,.download_ad,.easyazon-block,.ec-ads-remove-if-empty,.featured-ad,.featuredAdBox,.flash-advertisement,.footer-ad,.footer-ads,.footer_ad,.footerad,.forumAd,.gallery-ad,.google-sponsored,.googleAdSense,.googleAds,.greyAd,.has-ad,.hasads,.header-ad,.headerAd,.header_ad,.header_ad_center,.header_advert,.headerad,.headerads,.home-ad,.home-ads,.homeAd,.homead,.homepage-ad,.homepage_ads,.horizontal_ad,.img_ad,.imgad,.inner_ad,.innerad,.insert-post-ads,.interstitial_ad_wrapper,.ipsAd,.item-ads,.item-container-ad,.js-sticky-ad,.leaderboard-ad,.leaderboard-ads,.leftAd,.leftad,.list-ad,.list-ads,.listad,.logo-ad,.marketing-ad,.mid_ad,.middle_AD,.mod-adopenx,.module-ad,.nav-ad,.newsAd,.node-ad,.oasad,.oio-banner-zone,.openx,.overlay-ads,.page-ad,.page_ad,.plainAd,.playerAd,.player_ad,.player_hover_ad,.pm-ad,.post-ad,.post-sponsored,.post_ad,.postad,.premiumAdOverlay,.premiumAdOverlayClose,.promoAd,.promo_ad,.pub_300x250,.pub_300x250m,.pub_728x90,.publicidade,.pushdown-ad,.rail-ad,.rbRectAd,.rectangle_ad,.refreshAds,.region-top-ad-position,.reklam,.reklama,.reportAdLink,.resultad,.review-ad,.right-ad,.rightAd,.right_ad,.right_ads_column,.rightad,.rightadv,.searchAds,.searchad,.searchads,.section-sponsor,.showAd,.side-ad,.side-bar-ad-position1,.sideAd,.sidebar-ads,.single-ad,.singleAd,.skinAd,.sky_ad,.skyscraperAd,.slide-ad,.smallAd,.small_ad,.smallads,.sponsor-box,.sponsor-logo,.sponsorBlock,.sponsorBottom,.sponsoredLinks,.sponsorlink,.sticky-ad,.story-ad,.taboola-ad,.tc_ad_unit,.td-ad,.td-header-ad-wrap,.text-ad,.text-ad-links,.text-ads,.textAd,.text_ad,.text_ads,.textad,.textads,.top-ad,.top-ad-container,.top-ad-content,.top-ad-wrapper,.top-advert,.topAds,.top_ad,.top_ad_div,.top_ad_wrap,.top_ads,.topads,.tower-ad,.trc-content-sponsored,.trc_rbox .syndicatedItem,.trc_rbox_border_elm .syndicatedItem,.trc_rbox_div .syndicatedItem,.trc_related_container div[data-item-syndicated="true"],.type_ads_default,.view_ad,.wideAd,.withAds,.wnad,.wpInsertInPostAd,.wp_bannerize,.yom-ad,[href^="http://join.seemygf.com/track/"],[href^="http://myalternativegflink.com/track/"],[href^="http://secure.18exgfs.com/track/"],[href^="http://secure.badassgirlfriends.com/track/"],[href^="http://secure.chatrevenge.com/track/"],[href^="http://secure.fubilov.com/track/"],[href^="http://secure.hotgfvideos.com/track/"],[href^="http://secure.mynngf.com/track/"],[href^="http://secure.obsessedwithmyself.com/track/"],[href^="http://secure.slutswithphones.com/track/"],[href^="http://secure.watchmygf.com/track/"],a[href*=".trust.zone"],a[href*="/adrotate-out.php?"],a[href*="marketgid.com/"],a[href*="medicinetizer.ru"],a[href*="runetki.com"],a[href^="http://ad-emea.doubleclick.net/"],a[href^="http://ad.doubleclick.net/"],a[href^="http://adfarm.mediaplex.com/"],a[href^="http://ads.betfair.com/redirect.aspx?"],a[href^="http://adserving.unibet.com/"],a[href^="http://adultfriendfinder.com/p/register.cgi?pid="],a[href^="http://affiliate.coral.co.uk/processing/"],a[href^="http://marketgid.com"],a[href^="http://mgid.com/"],a[href^="http://online.ladbrokes.com/promoRedirect?"],a[href^="http://pubads.g.doubleclick.net/"],a[href^="http://us.marketgid.com"],a[href^="http://www.adskeeper.co.uk/"],a[href^="http://www.fbooksluts.com/"],a[href^="http://www.fleshlight.com/"],a[href^="http://www.liutilities.com/"],a[href^="http://www.socialsex.com/"],a[href^="http://www.yourfuckbook.com/?"],div[id^="MarketGid"],div[id^="advads-"],div[id^="dfp-ad-"],div[id^="div-gpt-ad"],div[id^="google_ads_iframe_"],div[itemtype="http://schema.org/WPAdBlock"],iframe[id^="google_ads_frame"],iframe[id^="google_ads_iframe"],iframe[src^="http://ad.yieldmanager.com/"] {display: none !important; color: #b6e791 !important; background-color: #53c2cb !important;}</style></head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Entropía_información rootpage-Entropía_información skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="siteNotice" class="mw-body-content"><div id="centralNotice"></div><!-- CentralNotice --></div><div class="mw-indicators mw-body-content">
</div>
<h1 id="firstHeading" class="firstHeading" lang="es">Entropía (información)</h1>			<div id="bodyContent" class="mw-body-content">
				<div id="siteSub" class="noprint">De Wikipedia, la enciclopedia libre</div>				<div id="contentSub"></div>
								<div id="jump-to-nav" class="mw-jump">
					Saltar a:					<a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#mw-head">navegación</a>, 					<a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#p-search">búsqueda</a>
				</div>
				<div id="mw-content-text" lang="es" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div class="rellink noprint">Para otros usos de este término, véase <a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(desambiguaci%C3%B3n)" class="mw-disambig" title="Entropía (desambiguación)">Entropía (desambiguación)</a>.</div>
<p>En el ámbito de la <a href="https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n" title="Teoría de la información">teoría de la información</a> la <b>entropía</b>, también llamada <b>entropía de la información</b> y <b>entropía de Shannon</b> (en honor a <a href="https://es.wikipedia.org/wiki/Claude_E._Shannon" class="mw-redirect" title="Claude E. Shannon">Claude E. Shannon</a>), mide la incertidumbre de una <a href="https://es.wikipedia.org/wiki/Fuente_de_informaci%C3%B3n" class="mw-redirect" title="Fuente de información">fuente de información</a>.</p>
<p>La entropía también se puede considerar como la cantidad de información promedio que contienen los símbolos usados. Los símbolos con menor probabilidad son los que aportan mayor información; por ejemplo, si se considera como sistema de símbolos a las palabras en un texto, palabras frecuentes como «que», «el», «a» aportan poca información, mientras que palabras menos frecuentes como «corren», «niño», «perro» aportan más información. Si de un texto dado borramos un «que», seguramente no afectará a la comprensión y se sobreentenderá, no siendo así si borramos la palabra «niño» del mismo texto original. Cuando todos los símbolos son igualmente probables (distribución de probabilidad plana), todos aportan información relevante y la entropía es máxima.</p>
<p>El concepto <b>entropía</b> es usado en <a href="https://es.wikipedia.org/wiki/Termodin%C3%A1mica" title="Termodinámica">termodinámica</a>, <a href="https://es.wikipedia.org/wiki/Mec%C3%A1nica_estad%C3%ADstica" class="mw-redirect" title="Mecánica estadística">mecánica estadística</a> y <a href="https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n" title="Teoría de la información">teoría de la información</a>. En todos los casos la entropía se concibe como una «medida del desorden» o la «peculiaridad de ciertas combinaciones». La entropía puede ser considerada como una medida de la incertidumbre y de la información necesaria para, en cualquier proceso, poder acotar, reducir o eliminar la incertidumbre. Resulta que el concepto de información y el de entropía están básicamente relacionados entre sí, aunque se necesitaron años de desarrollo de la <a href="https://es.wikipedia.org/wiki/Mec%C3%A1nica_estad%C3%ADstica" class="mw-redirect" title="Mecánica estadística">mecánica estadística</a> y de la <a href="https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n" title="Teoría de la información">teoría de la información</a> antes de que esto fuera percibido.</p>
<p></p>
<div id="toc" class="toc">
<div class="toctitle">
<h2>Índice</h2>
<span class="toctoggle">&nbsp;[<a role="button" tabindex="0" class="togglelink">ocultar</a>]&nbsp;</span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Relación_con_la_entropía_termodinámica"><span class="tocnumber">1</span> <span class="toctext">Relación con la entropía termodinámica</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Concepto_intuitivo"><span class="tocnumber">2</span> <span class="toctext">Concepto intuitivo</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Definición_formal"><span class="tocnumber">3</span> <span class="toctext">Definición formal</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Ejemplos"><span class="tocnumber">3.1</span> <span class="toctext">Ejemplos</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Información_mutua"><span class="tocnumber">3.2</span> <span class="toctext">Información mutua</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Propiedades"><span class="tocnumber">4</span> <span class="toctext">Propiedades</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Codificador_óptimo"><span class="tocnumber">5</span> <span class="toctext">Codificador óptimo</span></a>
<ul>
<li class="toclevel-2 tocsection-8"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Ejemplo"><span class="tocnumber">5.1</span> <span class="toctext">Ejemplo</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Entropía_condicional"><span class="tocnumber">6</span> <span class="toctext">Entropía condicional</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Aplicación_en_criptoanálisis"><span class="tocnumber">6.1</span> <span class="toctext">Aplicación en criptoanálisis</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Ejemplo_2"><span class="tocnumber">6.2</span> <span class="toctext">Ejemplo</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-12"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Entropía_de_un_proceso_estocástico"><span class="tocnumber">7</span> <span class="toctext">Entropía de un proceso estocástico</span></a>
<ul>
<li class="toclevel-2 tocsection-13"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Ratio_de_entropía"><span class="tocnumber">7.1</span> <span class="toctext">Ratio de entropía</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Véase_también"><span class="tocnumber">8</span> <span class="toctext">Véase también</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Notas_y_eferencias"><span class="tocnumber">9</span> <span class="toctext">Notas y eferencias</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Referencias"><span class="tocnumber">9.1</span> <span class="toctext">Referencias</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Bibliografía"><span class="tocnumber">9.2</span> <span class="toctext">Bibliografía</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-18"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#Enlaces_externos"><span class="tocnumber">10</span> <span class="toctext">Enlaces externos</span></a></li>
</ul>
</div>
<p></p>
<h2><span id="Relaci.C3.B3n_con_la_entrop.C3.ADa_termodin.C3.A1mica"></span><span class="mw-headline" id="Relación_con_la_entropía_termodinámica">Relación con la entropía termodinámica</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=1" title="Editar sección: Relación con la entropía termodinámica">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>La entropía de la teoría de la información está estrechamente relacionada con la <a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(termodin%C3%A1mica)" class="mw-redirect" title="Entropía (termodinámica)">entropía termodinámica</a>. En la termodinámica se estudia un sistema de partículas cuyos estados X (usualmente posición y velocidad) tienen una cierta <a href="https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad" title="Distribución de probabilidad">distribución de probabilidad</a>, pudiendo ocupar varios microestados posibles (equivalentes a los símbolos en la teoría de la información). La entropía termodinámica es igual a la entropía de la teoría de la información de esa distribución (medida usando el <a href="https://es.wikipedia.org/wiki/Logaritmo_neperiano" title="Logaritmo neperiano">logaritmo neperiano</a>) multiplicada por la <a href="https://es.wikipedia.org/wiki/Constante_de_Boltzmann" title="Constante de Boltzmann">constante de Boltzmann</a> k, la cual permite pasar de nats (unidad semejante al bit) a J/K. Cuando todos los microestados son igualmente probables, la entropía termodinámica toma la forma k log(N). En un sistema aislado, la interacción entre las partículas tiende a aumentar su dispersión, afectando sus posiciones y sus velocidades, lo que causa que la entropía de la distribución aumente con el tiempo hasta llegar a un cierto máximo (cuando el mismo sistema es lo más homogéneo y desorganizado posible); lo que es denominado <a href="https://es.wikipedia.org/wiki/Segunda_ley_de_la_termodin%C3%A1mica" class="mw-redirect" title="Segunda ley de la termodinámica">segunda ley de la termodinámica</a>. La diferencia entre la cantidad de entropía que tiene un sistema y el máximo que puede llegar a tener se denomina <a href="https://es.wikipedia.org/wiki/Neguentrop%C3%ADa" title="Neguentropía">neguentropía</a>, y representa la cantidad de organización interna que tiene el sistema. A partir de esta última se puede definir la <a href="https://es.wikipedia.org/wiki/Energ%C3%ADa_libre_de_Gibbs" class="mw-redirect" title="Energía libre de Gibbs">energía libre de Gibbs</a>, que indica la energía que puede liberar el sistema al aumentar la entropía hasta su máximo y puede ser transformada en trabajo (energía mecánica útil) usando una <a href="https://es.wikipedia.org/wiki/Ciclo_de_carnot" class="mw-redirect" title="Ciclo de carnot">máquina ideal de Carnot</a>. Cuando un sistema recibe un flujo de calor, las velocidades de las partículas aumentan, lo que dispersa la distribución y hace aumentar así la entropía. Así, el flujo de calor produce un flujo de entropía en la misma dirección.</p>
<h2><span class="mw-headline" id="Concepto_intuitivo">Concepto intuitivo</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=2" title="Editar sección: Concepto intuitivo">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:222px;"><a href="https://commons.wikimedia.org/wiki/File:Binary_entropy_plot.svg" class="image"><img alt="" src="./Entropía (información)_files/220px-Binary_entropy_plot.svg.png" width="220" height="220" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Binary_entropy_plot.svg/330px-Binary_entropy_plot.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/22/Binary_entropy_plot.svg/440px-Binary_entropy_plot.svg.png 2x" data-file-width="300" data-file-height="300"></a>
<div class="thumbcaption">
<div class="magnify"><a href="https://es.wikipedia.org/wiki/Archivo:Binary_entropy_plot.svg" class="internal" title="Aumentar"></a></div>
Entropía de la información en un <a href="https://es.wikipedia.org/wiki/Ensayo_de_Bernoulli" title="Ensayo de Bernoulli">ensayo de Bernoulli</a> <i>X</i> (experimento aleatorio en que X puede tomar los valores 0 o 1). La entropía depende de la probabilidad P(X=1) de que X tome el valor 1. Cuando P(X=1)=0.5, todos los resultados posibles son igualmente probables, por lo que el resultado es poco predecible y la entropía es máxima.</div>
</div>
</div>
<p>El concepto básico de entropía en <a href="https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n" title="Teoría de la información">teoría de la información</a> tiene mucho que ver con la <a href="https://es.wikipedia.org/wiki/Incertidumbre_(metrolog%C3%ADa)" title="Incertidumbre (metrología)">incertidumbre</a> que existe en cualquier experimento o señal aleatoria. Es también la cantidad de «<a href="https://es.wikipedia.org/wiki/Ruido_(comunicaci%C3%B3n)" title="Ruido (comunicación)">ruido</a>» o «desorden» que contiene o libera un sistema. De esta forma, podremos hablar de la cantidad de información que lleva una señal.</p>
<p>Como ejemplo, consideremos algún texto escrito en <a href="https://es.wikipedia.org/wiki/Idioma_espa%C3%B1ol" title="Idioma español">español</a>, codificado como una cadena de letras, espacios y <a href="https://es.wikipedia.org/wiki/Signos_de_puntuaci%C3%B3n" class="mw-redirect" title="Signos de puntuación">signos de puntuación</a> (nuestra señal será una cadena de caracteres). Ya que, estadísticamente, algunos caracteres no son muy comunes (por ejemplo, «w»), mientras otros sí lo son (como la «a»), la cadena de caracteres no será tan "aleatoria" como podría llegar a ser. Obviamente, no podemos predecir con exactitud cuál será el siguiente carácter en la cadena, y eso la haría aparentemente aleatoria. Pero es la entropía la encargada de medir precisamente esa aleatoriedad, y fue presentada por Shannon en su artículo de <a href="https://es.wikipedia.org/wiki/1948" title="1948">1948</a>, <a rel="nofollow" class="external text" href="http://cm.bell-labs.com/cm/ms/what/shannonday/paper.html"><i>A Mathematical Theory of Communication</i></a> ("<a href="https://es.wikipedia.org/wiki/Una_teor%C3%ADa_matem%C3%A1tica_de_la_comunicaci%C3%B3n" title="Una teoría matemática de la comunicación">Una teoría matemática de la comunicación</a>", en inglés).</p>
<p>Shannon ofrece una definición de entropía que satisface las siguientes afirmaciones:</p>
<ul>
<li>La medida de información debe ser <i>proporcional</i> (<a href="https://es.wikipedia.org/wiki/Lineal" title="Lineal">lineal</a> continua). Es decir, el cambio pequeño en una de las probabilidades de aparición de uno de los elementos de la señal debe cambiar poco la entropía.</li>
<li>Si todos los elementos de la señal son equiprobables (igual de probables) a la hora de aparecer, entonces la entropía será máxima.</li>
</ul>
<p>Ejemplos de máxima entropía: Suponiendo que estamos a la espera de un texto, por ejemplo un cable con un mensaje. En dicho cable solo se reciben las letras en minúscula de la a hasta la z, entonces si el mensaje que nos llega es "qalmnbphijcdgketrsfuvxyzwño" el cual posee una longitud de 27 caracteres, se puede decir que este mensaje llega a nosotros con la máxima entropía (o desorden posible); ya que es poco probable que se pueda pronosticar la entrada de caracteres, pues estos no se repiten ni están ordenados en una forma predecible.</p>
<h2><span id="Definici.C3.B3n_formal"></span><span class="mw-headline" id="Definición_formal">Definición formal</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=3" title="Editar sección: Definición formal">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Supongamos que un evento (variable aleatoria) tiene un grado de indeterminación inicial igual a <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.222ex; height:2.176ex;" alt="k"></span> (i.e. existen <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.222ex; height:2.176ex;" alt="k"></span> estados posibles) y supongamos todos los estados equiprobables. Entonces la probabilidad de que se dé una de esas combinaciones será <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p=1/k}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/bf99a68f74aa9fcda93904202b2f9bc4225b6ac6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.079ex; width:7.935ex; height:2.843ex;" alt="{\displaystyle p=1/k}"></span>. Luego podemos representar la expresión <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{i}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/01acb7953ba52c2aa44264b5d0f8fd223aa178a2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.824ex; height:2.009ex;" alt="c_i"></span> como:<sup id="cite_ref-1" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-1"><span class="corchete-llamada">[</span>a<span class="corchete-llamada">]</span></a></sup>​</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>p</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mrow class="MJX-TeXAtom-OP">
            <munder>
              <mrow>
                <msub>
                  <mi>log</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>⁡<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo stretchy="false">)</mo>
              </mrow>
              <mo>⏟<!-- ⏟ --></mo>
            </munder>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>=</mo>
            <mn>0</mn>
          </mrow>
        </munder>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>p</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>p</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{i}=\log _{2}(k)=\log _{2}[1/(1/k)]=\log _{2}(1/p)=\underbrace {\log _{2}(1)} _{=0}-\log _{2}(p)=-\log _{2}(p)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/60e1bbf8ab152a7dae8420dce7c60b1467ab16d7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -4.338ex; width:73.303ex; height:6.343ex;" alt="{\displaystyle c_{i}=\log _{2}(k)=\log _{2}[1/(1/k)]=\log _{2}(1/p)=\underbrace {\log _{2}(1)} _{=0}-\log _{2}(p)=-\log _{2}(p)}"></span></p>
</blockquote>
<p>Si ahora cada uno de los <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.222ex; height:2.176ex;" alt="k"></span> estados tiene una probabilidad <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{i}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/5bab39399bf5424f25d957cdc57c84a0622626d2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.079ex; width:2.066ex; height:2.009ex;" alt="{\displaystyle p_{i}}"></span>, entonces la entropía vendrá dada por la suma ponderada de la cantidad de información:<sup id="cite_ref-2" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-2"><span class="corchete-llamada">[</span>1<span class="corchete-llamada">]</span></a></sup>​<sup id="cite_ref-3" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-3"><span class="corchete-llamada">[</span>b<span class="corchete-llamada">]</span></a></sup>​</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>−<!-- − --></mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munderover>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H=-p_{1}\log _{2}(p_{1})-p_{2}\log _{2}(p_{2})-....-p_{k}\log _{2}(p_{k})=-\sum _{i=1}^{k}p_{i}\log _{2}(p_{i})}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/06176cae144d11b6dc8245e5bf22b59e60e76ddc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:69.354ex; height:7.343ex;" alt="{\displaystyle H=-p_{1}\log _{2}(p_{1})-p_{2}\log _{2}(p_{2})-....-p_{k}\log _{2}(p_{k})=-\sum _{i=1}^{k}p_{i}\log _{2}(p_{i})}"></span></p>
</blockquote>
<p>Por lo tanto, la entropía de un mensaje <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.99ex; height:2.176ex;" alt="X"></span>, denotado por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/bd232b6fb5ea803efc1154d2efb0c3fe00a4531b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.895ex; height:2.843ex;" alt="{\displaystyle H(X)}"></span>, es el valor medio ponderado de la cantidad de información de los diversos estados del mensaje:</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)=-\sum _{i}p(x_{i})\log _{2}p(x_{i})}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/8c6296040ac1e3f9e0ba8c2934bab835f3c6bb85" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:30.115ex; height:5.509ex;" alt="{\displaystyle H(X)=-\sum _{i}p(x_{i})\log _{2}p(x_{i})}"></span></p>
</blockquote>
<p>que representa una medida de la incertidumbre media acerca de una variable aleatoria y por tanto de la cantidad de información.</p>
<p><br></p>
<h3><span class="mw-headline" id="Ejemplos">Ejemplos</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=4" title="Editar sección: Ejemplos">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li>La entropía de un mensaje M de longitud 1 carácter que utiliza el conjunto de caracteres ASCII, suponiendo una equiprobabilidad en los 256 caracteres ASCII, será:</li>
</ul>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>256</mn>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>8</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(M)=\log _{2}(256)=8}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/9c0a67acb413679aa32b539e9d0aa40042d50905" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:23.161ex; height:2.843ex;" alt="{\displaystyle H(M)=\log _{2}(256)=8}"></span></dd>
</dl>
<ul>
<li>Supongamos que el número de estados de un mensaje es igual a 3, M<sub>1</sub>, M<sub>2</sub> y M<sub>3</sub> donde la probabilidad de M<sub>1</sub> es 50&nbsp;%, la de M<sub>2</sub> 25&nbsp;% y la de M<sub>3</sub> 25&nbsp;%. Por tanto, la entropía de la información es:</li>
</ul>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>2</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>2</mn>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>4</mn>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>4</mn>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mo>,</mo>
        <mn>5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(M)=1/2\log _{2}(2)+1/4\log _{2}(4)+1/4\log _{2}(4)=1,5}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/d84d40bb22d1bc22ec2c623e8a5f46a9550d3845" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:54.588ex; height:2.843ex;" alt="{\displaystyle H(M)=1/2\log _{2}(2)+1/4\log _{2}(4)+1/4\log _{2}(4)=1,5}"></span></dd>
</dl>
<h3><span id="Informaci.C3.B3n_mutua"></span><span class="mw-headline" id="Información_mutua">Información mutua</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=5" title="Editar sección: Información mutua">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>La entropía puede verse como caso especial de la <a href="https://es.wikipedia.org/wiki/Informaci%C3%B3n_mutua" title="Información mutua">información mutua</a>. La <a href="https://es.wikipedia.org/wiki/Informaci%C3%B3n_mutua" title="Información mutua">información mutua</a> de dos <a href="https://es.wikipedia.org/wiki/Variable_aleatoria" title="Variable aleatoria">variables aleatorias</a>, denotado por I(X;Y), es una <a href="https://es.wikipedia.org/wiki/Cantidad" title="Cantidad">cantidad</a> que mide la dependencia mutua de las dos <a href="https://es.wikipedia.org/wiki/Variable_(programaci%C3%B3n)" title="Variable (programación)">variables</a>; es decir, mide la reducción de la incertidumbre (<b>entropía</b>) de una variable aleatoria, X, debido al conocimiento del valor de otra variable aleatoria, Y.<sup id="cite_ref-4" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-4"><span class="corchete-llamada">[</span>2<span class="corchete-llamada">]</span></a></sup>​ De la definición podemos concluir que, si X e Y son iguales, entonces I(X;X)=H(X).</p>
<h2><span class="mw-headline" id="Propiedades">Propiedades</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=6" title="Editar sección: Propiedades">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>La entropía tiene las siguientes propiedades:</p>
<ol>
<li>La entropía es no negativa. Esto es evidente ya que al ser <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{i}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/5bab39399bf5424f25d957cdc57c84a0622626d2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.079ex; width:2.066ex; height:2.009ex;" alt="{\displaystyle p_{i}}"></span> una probabilidad entonces <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>0</mn>
        <mo>&lt;</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>≤<!-- ≤ --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 0&lt;p_{i}\leq 1}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e6c4c5292b1dfe22a445a72e9782fd92569a2fe1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.551ex; height:2.509ex;" alt="{\displaystyle 0&lt;p_{i}\leq 1}"></span>. Por tanto, podemos decir que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>≤<!-- ≤ --></mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \log _{2}p_{i}\leq 0}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/eca15ec0da9d92f724a740182c514b7fa93eb85e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.721ex; height:2.676ex;" alt="{\displaystyle \log _{2}p_{i}\leq 0}"></span> y por tanto <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>−<!-- − --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>≥<!-- ≥ --></mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle -\log _{2}p_{i}\geq 0}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/4fc092605d9d3bc1cb6a4b956eb6aa8875b3ac49" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.926ex; height:2.676ex;" alt="{\displaystyle -\log _{2}p_{i}\geq 0}"></span></li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo>≤<!-- ≤ --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>a</mi>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>n</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H\leq \log _{a}(n)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/bb42da2099a7acafd571a31b3ef8999cc348cc1d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.531ex; height:2.843ex;" alt="{\displaystyle H\leq \log _{a}(n)}"></span> Es decir, la entropía H está acotada superiormente (cuando es máxima) y no supone pérdida de información.</li>
<li>Dado un proceso con posibles resultados {A<sub>1</sub>,..,A<sub>n</sub>} con probabilidades relativas p<sub>1</sub>,...,p<sub>n</sub>, la función <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>…<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace"></mspace>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(p_{1},\dots ,p_{n})\,}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/961e67fbbbbfb6b0796c6cb6420bff00f0a17a3c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.148ex; height:2.843ex;" alt="{\displaystyle H(p_{1},\dots ,p_{n})\,}"></span> es máxima en el caso de que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo>⋯<!-- ⋯ --></mo>
        <mo>=</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>n</mi>
        <mspace width="thinmathspace"></mspace>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{1}=\dots =p_{n}=1/n\,}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/dd4d0fc316b1a5dee94b68d5f54988c9f4ff2484" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.079ex; width:20.925ex; height:2.843ex;" alt="{\displaystyle p_{1}=\dots =p_{n}=1/n\,}"></span>. El resultado es intuitivo ya que tenemos la mayor incertidumbre del mensaje, cuando los valores posibles de la variable son equiprobables</li>
<li>Dado un proceso con posibles resultados {A<sub>1</sub>,..,A<sub>n</sub>} con probabilidades relativas p<sub>1</sub>,...,p<sub>n</sub>, la función <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>…<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace"></mspace>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(p_{1},\dots ,p_{n})\,}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/961e67fbbbbfb6b0796c6cb6420bff00f0a17a3c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.148ex; height:2.843ex;" alt="{\displaystyle H(p_{1},\dots ,p_{n})\,}"></span> es nula en el caso de que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{i}=0}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c133bcdae2383393aa80cd103e8b8061d35284e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.079ex; width:6.348ex; height:2.509ex;" alt="{\displaystyle p_{i}=0}"></span> para todo i, excepto para una clase, tal que: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{j}=1}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c808a7c6f92709638efad3b98c95e604f0f4bc6f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; margin-left: -0.079ex; width:6.458ex; height:2.843ex;" alt="{\displaystyle p_{j}=1}"></span>. De forma intuitiva podemos pensar que cuando uno o más estados tienen una probabilidad alta, disminuye significativamente la entropía porque, como es lógico, existe una menor incertidumbre respecto al mensaje que se recibirá.</li>
</ol>
<h2><span id="Codificador_.C3.B3ptimo"></span><span class="mw-headline" id="Codificador_óptimo">Codificador óptimo</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=7" title="Editar sección: Codificador óptimo">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Un <b>codificador óptimo</b> es aquel que utiliza el mínimo número de bits para codificar un mensaje. Un codificador óptimo usará códigos cortos para codificar mensajes frecuentes y dejará los códigos de mayor longitud para aquellos mensajes que sean menos frecuentes. De esta forma se optimiza el rendimiento del canal o zona de almacenamiento y el sistema es eficiente en términos del número de bits para representar el mensaje.</p>
<p>Por ejemplo, el <a href="https://es.wikipedia.org/wiki/C%C3%B3digo_Morse" class="mw-redirect" title="Código Morse">código Morse</a> se aprovecha de este principio para optimizar el número de caracteres a transmitir a partir del estudio de las letras más frecuentes del alfabeto inglés. Aunque el código Morse no es un codificador óptimo, asigna a las letras más frecuente códigos más cortos. Otro ejemplo sería el <a href="https://es.wikipedia.org/wiki/Algoritmo_de_Huffman" title="Algoritmo de Huffman">algoritmo de Huffman</a> de codificación que sirve para compactar información.<sup id="cite_ref-5" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-5"><span class="corchete-llamada">[</span>3<span class="corchete-llamada">]</span></a></sup>​ Este método se basa en el <b>codificador óptimo</b>. Para ello lo primero que hace es recorrer toda la información para encontrar la frecuencia de los caracteres y luego a partir de esta información busca el codificador óptimo por medio de árboles binarios. Algunas técnicas de compresión como <a href="https://es.wikipedia.org/wiki/LZW" title="LZW">LZW</a> o <a href="https://es.wikipedia.org/wiki/Deflaci%C3%B3n_(algoritmo)" title="Deflación (algoritmo)">deflación</a> no usan probabilidades de los símbolos aislados, sino que usan las probabilidades conjuntas de pequeñas secuencias de símbolos para codificar el mensaje, por lo que pueden lograr un nivel de compresión mayor.</p>
<p>Podemos construir un codificador óptimo basándonos en la entropía de una variable aleatoria de información X. En efecto, la entropía nos da el <b>número medio</b> de bits (si usamos logaritmos de base 2) necesarios para codificar el mensaje a través de un <b>codificador óptimo</b> y por tanto nos determina el límite máximo al que se puede comprimir un mensaje usando un enfoque símbolo a símbolo sin ninguna pérdida de información (demostrado analíticamente por Shannon), el límite de compresión (en bits) es igual a la entropía multiplicada por el largo del mensaje. Reescribiendo la ecuación de cálculo de la entropía llegamos a que:</p>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mo>−<!-- − --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">[</mo>
        <mi>l</mi>
        <mi>o</mi>
        <msub>
          <mi>g</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>x</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)=-\sum _{i}p(x_{i})\log _{2}p(x_{i})=\sum _{i}-p(x_{i})\log _{2}p(x_{i})=\sum _{i}p(x_{i})[log_{2}(1)-\log _{2}(p(x_{i}))]=\sum _{x}p(x)\log _{2}(1/p(x))}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/2efc6a2ee2e3523ccdf26f774d0aba23a576fc53" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:112.401ex; height:5.509ex;" alt="{\displaystyle H(X)=-\sum _{i}p(x_{i})\log _{2}p(x_{i})=\sum _{i}-p(x_{i})\log _{2}p(x_{i})=\sum _{i}p(x_{i})[log_{2}(1)-\log _{2}(p(x_{i}))]=\sum _{x}p(x)\log _{2}(1/p(x))}"></span></dd>
</dl>
<p>Por lo tanto, la información (que se encuentra definida en bits, dado que la base del logaritmo es 2) que aporta un determinado valor o símbolo <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mspace width="thinmathspace"></mspace>
        <mspace width="negativethinmathspace"></mspace>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}\,\!}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/17b1da03287bd6ea89ddc72e104976033b030213" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-right: -0.387ex; width:2.534ex; height:2.009ex;" alt="{\displaystyle x_{i}\,\!}"></span> de una variable aleatoria discreta <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
        <mspace width="thinmathspace"></mspace>
        <mspace width="negativethinmathspace"></mspace>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X\,\!}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/98c6c570e3a2c130fc8d968160962b5e0fe4b0e0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; margin-right: -0.387ex; width:2.378ex; height:2.176ex;" alt="{\displaystyle X\,\!}"></span> se define como:</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>I</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi>p</mi>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>x</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
            </mrow>
          </msub>
          <mo stretchy="false">)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle I(x_{i})=\log _{2}{\frac {1}{p(x_{i})}}=-\log _{2}{p(x_{i})}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/3d9045b2778845d2f332f9082ee6b87f63ed903e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.671ex; width:33.637ex; height:6.009ex;" alt="{\displaystyle I(x_{i})=\log _{2}{\frac {1}{p(x_{i})}}=-\log _{2}{p(x_{i})}}"></span></p>
</blockquote>
<p>Esta expresión representa el número necesario de bits para codificar el mensaje x en el <b>codificador óptimo</b> y por tanto la entropía también se puede considerar como una medida de la información promedio contenida en cada símbolo del mensaje.</p>
<h3><span class="mw-headline" id="Ejemplo">Ejemplo</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=8" title="Editar sección: Ejemplo">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supongamos que el número de estados de un mensaje es igual a 3 M<sub>1</sub>, M<sub>2</sub> y M<sub>3</sub> donde la probabilidad de M<sub>1</sub> es 50&nbsp;%, la de M<sub>2</sub> 25&nbsp;% y la de M<sub>3</sub> 25&nbsp;%.</p>
<dl>
<dd>Para M<sub>1</sub> tenemos que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>M</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mn>2</mn>
        <mo>=</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \log _{2}[1/p(M_{1})]=\log _{2}2=1}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/6019f798535752dfdcd4c76b5dacfd64abda4a72" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.077ex; height:2.843ex;" alt="{\displaystyle \log _{2}[1/p(M_{1})]=\log _{2}2=1}"></span></dd>
<dd>Para M<sub>2</sub> tenemos que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>M</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mn>4</mn>
        <mo>=</mo>
        <mn>2</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \log _{2}[1/p(M_{2})]=\log _{2}4=2}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/8b9dfb5da06f179104722789b17c88be60c63339" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.077ex; height:2.843ex;" alt="{\displaystyle \log _{2}[1/p(M_{2})]=\log _{2}4=2}"></span></dd>
<dd>Para M<sub>3</sub> tenemos que <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>M</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mn>4</mn>
        <mo>=</mo>
        <mn>2</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \log _{2}[1/p(M_{3})]=\log _{2}4=2}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/2fa2cf09dfdbf4a923fe23d6dd2b99dd16b18b44" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.077ex; height:2.843ex;" alt="{\displaystyle \log _{2}[1/p(M_{3})]=\log _{2}4=2}"></span></dd>
</dl>
<p>Por tanto, en el codificador óptimo para transmitir M<sub>1</sub> hará falta un bit y para M<sub>2</sub> y M<sub>3</sub> será necesario contar con dos bits. Por ejemplo, podríamos codificar M<sub>1</sub> con "0", M<sub>2</sub> con "10" y M<sub>3</sub> con "11". Usando este convenio para codificar el mensaje M<sub>1</sub>M<sub>2</sub>M<sub>1</sub>M<sub>1</sub>M<sub>3</sub>M<sub>1</sub>M<sub>2</sub>M<sub>3</sub> usaríamos "010001101011" y por tanto 12 bits. El valor de la entropía sería:</p>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>2</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>2</mn>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>4</mn>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>4</mn>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mo>,</mo>
        <mn>5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)=1/2\log _{2}(2)+1/4\log _{2}(4)+1/4\log _{2}(4)=1,5}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/47179d8aff4f8ed931cc2325e74ccb02ba21be94" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:54.125ex; height:2.843ex;" alt="{\displaystyle H(X)=1/2\log _{2}(2)+1/4\log _{2}(4)+1/4\log _{2}(4)=1,5}"></span></dd>
</dl>
<p>Por tanto, el <b>codificador óptimo</b> necesita de media 1,5 bits para codificar cualquier valor de X.</p>
<h2><span id="Entrop.C3.ADa_condicional"></span><span class="mw-headline" id="Entropía_condicional">Entropía condicional</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=9" title="Editar sección: Entropía condicional">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<dl>
<dd><i>Véase también artículo dedicado:</i> <a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_condicional" title="Entropía condicional">Entropía condicional</a></dd>
</dl>
<p>Supongamos que en vez de tener una única variable aleatoria X, existe otra variable Y dependientes entre sí, es decir el conocimiento de una (por ejemplo, Y) entrega información sobre la otra (por ejemplo, X). Desde el punto de vista de la entropía de la información podemos decir que la información de Y disminuirá la incertidumbre de X. Por tanto, podemos decir que la entropía de X será condicional a Y, y por tanto:</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>,</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>x</mi>
            <mo>,</mo>
            <mi>y</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X,Y)=-\sum _{x,y}p(x,y)\log _{2}p(x,y)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e035db20d964e746f102ea0d82f397637b94d8b4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:35.75ex; height:5.843ex;" alt="{\displaystyle H(X,Y)=-\sum _{x,y}p(x,y)\log _{2}p(x,y)}"></span></p>
</blockquote>
<p>Como por el <a href="https://es.wikipedia.org/wiki/Teorema_de_Bayes" title="Teorema de Bayes">teorema de Bayes</a> tenemos que p(x,y)=p(y)p(x|y) donde p(x|y) es la probabilidad de que se dé un estado de X conocida Y, podemos decir:</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>y</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>x</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X|Y)=-\sum _{y}p(y)\sum _{x}p(x|y)\log _{2}p(x|y)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/112b19fa092953033348d4d3a93aa20f5d996c54" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:42.904ex; height:5.843ex;" alt="{\displaystyle H(X|Y)=-\sum _{y}p(y)\sum _{x}p(x|y)\log _{2}p(x|y)}"></span></p>
</blockquote>
<h3><span id="Aplicaci.C3.B3n_en_criptoan.C3.A1lisis"></span><span class="mw-headline" id="Aplicación_en_criptoanálisis">Aplicación en criptoanálisis</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=10" title="Editar sección: Aplicación en criptoanálisis">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>El concepto de entropía condicional es muy interesante en el campo del <a href="https://es.wikipedia.org/wiki/Criptoan%C3%A1lisis" title="Criptoanálisis">criptoanálisis</a>. Proporciona una herramienta para evaluar el grado de seguridad de los sistemas. Por ejemplo, para un sistema de <a href="https://es.wikipedia.org/wiki/Cifrado_(criptograf%C3%ADa)" title="Cifrado (criptografía)">cifrado</a> hay dos entropías condicionales interesantes:<sup id="cite_ref-6" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-6"><span class="corchete-llamada">[</span>4<span class="corchete-llamada">]</span></a></sup>​ Supongamos</p>
<ul>
<li>Un mensaje M<sub>1</sub> es sometido a un proceso de cifrado usando la clave K<sub>1</sub> obteniendo E(K<sub>1</sub>,M<sub>1</sub>)=C<sub>1</sub>.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>P</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P_{C}(K)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/bb720d931bf375e3f582663f4f180b28444a18b8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.898ex; height:2.843ex;" alt="{\displaystyle P_{C}(K)}"></span> representan la probabilidad condicional de la clave K dado el criptograma recibido C. A veces también se denota por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(K|C)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/25e0c3a00594caa9aeaa3936066c249f38f67d41" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.097ex; height:2.843ex;" alt="{\displaystyle P(K|C)}"></span></li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>P</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P_{C}(M)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/c40f463fb11f40893ed6890cdd8221ae2927f6a5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.274ex; height:2.843ex;" alt="{\displaystyle P_{C}(M)}"></span> representan la probabilidad condicional del mensaje M dado el criptograma recibido C. A veces también se denota por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(M|C)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/99f55c7418d149423a57101c879212cd8e804fca" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.473ex; height:2.843ex;" alt="{\displaystyle P(M|C)}"></span></li>
</ul>
<p>Entonces:</p>
<ul>
<li>Podemos calcular la entropía del conocimiento de la clave una vez conocido el texto cifrado, y por tanto medir la <b>equivocación del mensaje</b> (en inglés, <i>message equivocation</i>), <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{C}(K)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/dc985b20a27fa62ede24353d15fc3c2d097a75ac" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.337ex; height:2.843ex;" alt="{\displaystyle H_{C}(K)}"></span>, también denotada por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(K|C)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/6b43b99f801c5802653951be8e358b52f65ca5b5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.415ex; height:2.843ex;" alt="{\displaystyle H(K|C)}"></span>, mediante la fórmula:</li>
</ul>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<dl>
<dd>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
            <mo>,</mo>
            <mi>K</mi>
          </mrow>
        </munder>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>E</mi>
        <mo>,</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>P</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>E</mi>
              </mrow>
            </msub>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
          </mrow>
        </munder>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>E</mi>
        <mo stretchy="false">)</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>K</mi>
          </mrow>
        </munder>
        <msub>
          <mi>P</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>P</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>E</mi>
              </mrow>
            </msub>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{C}(K)=-\sum _{E,K}P(E,K)\log _{P_{E}}(K)=-\sum _{E}P(E)\sum _{K}P_{E}(K)\log _{P_{E}}(K)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/f7212a3973db304add2936a9a033f5756e1f45b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:69.943ex; height:5.843ex;" alt="{\displaystyle H_{C}(K)=-\sum _{E,K}P(E,K)\log _{P_{E}}(K)=-\sum _{E}P(E)\sum _{K}P_{E}(K)\log _{P_{E}}(K)}"></span></dd>
</dl>
</dd>
</dl>
</blockquote>
<dl>
<dd>La primera igualdad es por la definición de la entropía condicional y la segunda por aplicación del <a href="https://es.wikipedia.org/wiki/Teorema_de_Bayes" title="Teorema de Bayes">teorema de Bayes</a>.</dd>
<dd>Observar que si <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>K</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{C}(K)=0}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/27b2af626170380c7ad5f2c72bce8a9f2df2fb22" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:11.619ex; height:2.843ex;" alt="{\displaystyle H_{C}(K)=0}"></span> significa que se podrá romper el cifrado pues ya no hay incertidumbre. Esta anulación nos introduce en el concepto de <a href="https://es.wikipedia.org/wiki/Distancia_de_unicidad" title="Distancia de unicidad">distancia de unicidad</a>.</dd>
</dl>
<ul>
<li>Podemos calcular la entropía del conocimiento del mensaje una vez conocido el texto cifrado, y por tanto medir la <b>equivocación de la clave</b> (en inglés, <i>key equivocation</i>), <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{C}(M)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/83790026fe0673ffe3570bb98cf92741d484fc05" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.713ex; height:2.843ex;" alt="{\displaystyle H_{C}(M)}"></span>, también denotada por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(M|C)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/b9f32a3dc7eab157d37dae93eede0669feae1b06" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.791ex; height:2.843ex;" alt="{\displaystyle H(M|C)}"></span>, mediante la fórmula:</li>
</ul>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<dl>
<dd>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>C</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
            <mo>,</mo>
            <mi>M</mi>
          </mrow>
        </munder>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>E</mi>
        <mo>,</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>P</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>E</mi>
              </mrow>
            </msub>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
          </mrow>
        </munder>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>E</mi>
        <mo stretchy="false">)</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munder>
        <msub>
          <mi>P</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>E</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>P</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>E</mi>
              </mrow>
            </msub>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{C}(M)=-\sum _{E,M}P(E,M)\log _{P_{E}}(M)=-\sum _{E}P(E)\sum _{M}P_{E}(M)\log _{P_{E}}(M)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/ca0b56e873cc987a90b999e6efb76a9e5a95feb9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:71.921ex; height:5.843ex;" alt="{\displaystyle H_{C}(M)=-\sum _{E,M}P(E,M)\log _{P_{E}}(M)=-\sum _{E}P(E)\sum _{M}P_{E}(M)\log _{P_{E}}(M)}"></span></dd>
</dl>
</dd>
</dl>
</blockquote>
<dl>
<dd>La primera igualdad es por la definición de la entropía condicional y la segunda por aplicación del <a href="https://es.wikipedia.org/wiki/Teorema_de_Bayes" title="Teorema de Bayes">teorema de Bayes</a>.</dd>
</dl>
<h3><span class="mw-headline" id="Ejemplo_2">Ejemplo</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=11" title="Editar sección: Ejemplo">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Supongamos una variable X con cuatro estados: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>4</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{1},x_{2},x_{3},x_{4}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/b84ce1cc896515faf3ee0de42ef17090c21ad097" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:12.74ex; height:2.009ex;" alt="{\displaystyle x_{1},x_{2},x_{3},x_{4}}"></span> todos equiprobables y por tanto <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(x_{i})=1/4}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/3a4a32b99929fbf7b5d31d7dd9f307d52eb1fbfb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.079ex; width:11.864ex; height:2.843ex;" alt="{\displaystyle p(x_{i})=1/4}"></span>. Existe además otra variable Y con tres estados; <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y_{1},y_{2},y_{3}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/07a18881628c46664fa75993d5a26f11ef06913e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:8.723ex; height:2.009ex;" alt="{\displaystyle y_{1},y_{2},y_{3}}"></span> con probabilidades <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>2</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(y_{1})=1/2}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/7d5c3c682618dae82ef93e00cb8d130a0193c62f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.079ex; width:11.928ex; height:2.843ex;" alt="{\displaystyle p(y_{1})=1/2}"></span> y <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>4</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(y_{2})=p(y_{3})=1/4}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e56dd68985b8b8fbc98a65d9f803a90b9288c69c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.079ex; width:20.258ex; height:2.843ex;" alt="{\displaystyle p(y_{2})=p(y_{3})=1/4}"></span>. Se conocen, además, las siguientes dependencias:</p>
<dl>
<dd>Si <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo>=</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y=y_{1}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/2d4b7f737fa1b9f6de5b0f7e647d2ba80e78e29f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.104ex; height:2.509ex;" alt="{\displaystyle Y=y_{1}}"></span> entonces los posibles valores de x son <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>4</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{1},x_{2},x_{3},x_{4}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/b84ce1cc896515faf3ee0de42ef17090c21ad097" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:12.74ex; height:2.009ex;" alt="{\displaystyle x_{1},x_{2},x_{3},x_{4}}"></span></dd>
<dd>Si <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo>=</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y=y_{2}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/42c5be2bcbc929fd00dbba72c14098893b1f399b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.104ex; height:2.509ex;" alt="{\displaystyle Y=y_{2}}"></span> entonces los posibles valores de x son <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{2},x_{3}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/716c5edca0cd292cddcfb1e62a25e7cf3d9eae49" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:5.848ex; height:2.009ex;" alt="{\displaystyle x_{2},x_{3}}"></span></dd>
<dd>Si <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo>=</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y=y_{3}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/54e886b2419f7b075c37785742fd3f121d1c7379" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.104ex; height:2.509ex;" alt="{\displaystyle Y=y_{3}}"></span> entonces los posibles valores de x son <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>4</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{3},x_{4}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/a42452f484dd7662299d0ee3a522e44ac25d8646" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:5.848ex; height:2.009ex;" alt="{\displaystyle x_{3},x_{4}}"></span></dd>
</dl>
<p>Aplicando las fórmulas tenemos:</p>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>2</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)=2}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/4b507bd6bd7ed021e253600a4471853814b75f1b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.177ex; height:2.843ex;" alt="{\displaystyle H(X)=2}"></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mo>,</mo>
        <mn>5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(Y)=1,5}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/f6fe38a2ce49957c5868afd6d3e4f5a4181a7556" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.187ex; height:2.843ex;" alt="{\displaystyle H(Y)=1,5}"></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1</mn>
        <mo>,</mo>
        <mn>5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X/Y)=1,5}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/7129a00f209138f0870d5d58694c700884689dd4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:15.351ex; height:2.843ex;" alt="{\displaystyle H(X/Y)=1,5}"></span></dd>
</dl>
<p>En este caso el conocimiento de la dependencia de X respecto Y reduce la entropía de X de 2 a 1,5.</p>
<h2><span id="Entrop.C3.ADa_de_un_proceso_estoc.C3.A1stico"></span><span class="mw-headline" id="Entropía_de_un_proceso_estocástico">Entropía de un proceso estocástico</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=12" title="Editar sección: Entropía de un proceso estocástico">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><sup id="cite_ref-cover_7-0" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-cover-7"><span class="corchete-llamada">[</span>5<span class="corchete-llamada">]</span></a></sup>​Un <a href="https://es.wikipedia.org/wiki/Proceso_estoc%C3%A1stico" title="Proceso estocástico">proceso estocástico</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{X_{i}\}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/3ba8a662382c1f121e79e3f1d518c575cb6c42c6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.088ex; height:2.843ex;" alt="{\displaystyle \{X_{i}\}}"></span> es una secuencia indexada de variables aleatorias. En general, puede haber dependencias entre las variables aleatorias. Para estudiar la probabilidad de cierto conjunto de valores se suele adoptar el siguiente convenio:</p>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mi>r</mi>
        <mo stretchy="false">[</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>=</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Pr[(X_{1},X_{2},...,X_{n})=(x_{1},x_{2},...,x_{n})]=p(x_{1},x_{2},...,x_{n})}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e63e90fa9fb95fcc126f978fab50a4cd54011c3e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:59.709ex; height:2.843ex;" alt="{\displaystyle Pr[(X_{1},X_{2},...,X_{n})=(x_{1},x_{2},...,x_{n})]=p(x_{1},x_{2},...,x_{n})}"></span></dd>
</dl>
<p>Sea <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
            <mo>,</mo>
            <mo>.</mo>
            <mo>.</mo>
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{X_{i}\}_{i=1,..n}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/57457cdf492c10d22f325ac664aeb3d3067c0379" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:10.398ex; height:3.009ex;" alt="{\displaystyle \{X_{i}\}_{i=1,..n}}"></span> un proceso estocástico de n variables aleatorias, y sea <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>A</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A^{n}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/f40057ac796fcce575670828684300e42bf8a227" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.979ex; height:2.343ex;" alt="{\displaystyle A^{n}}"></span> el conjunto de la posibles combinaciones de valores de <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
            <mo>,</mo>
            <mo>.</mo>
            <mo>.</mo>
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{X_{i}\}_{i=1,..n}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/57457cdf492c10d22f325ac664aeb3d3067c0379" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:10.398ex; height:3.009ex;" alt="{\displaystyle \{X_{i}\}_{i=1,..n}}"></span>. Se define la <b>entropía del proceso estocástico</b>, también llamada <b>entropía del n-grama</b> y denotado por <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{n}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e63458b04288bbe116a9a8037dfae0b36b2c639a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.168ex; height:2.509ex;" alt="{\displaystyle H_{n}}"></span>, como:</p>
<dl>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>H</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>s</mi>
            <mo>∈<!-- ∈ --></mo>
            <msup>
              <mi>A</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msup>
          </mrow>
        </munder>
        <mo>−<!-- − --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>s</mi>
        <mo stretchy="false">)</mo>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>s</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H_{n}=H(X_{1},...,X_{n})=\sum _{s\in A^{n}}-P((X_{1},...,X_{n})=s)\log P((X_{1},...,X_{n})=s)}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/e3503a3fb2d5888f3050fd9a6c9c9231c88697de" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:76.754ex; height:5.843ex;" alt="{\displaystyle H_{n}=H(X_{1},...,X_{n})=\sum _{s\in A^{n}}-P((X_{1},...,X_{n})=s)\log P((X_{1},...,X_{n})=s)}"></span></dd>
</dl>
<h3><span id="Ratio_de_entrop.C3.ADa"></span><span class="mw-headline" id="Ratio_de_entropía">Ratio de entropía</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=13" title="Editar sección: Ratio de entropía">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<dl>
<dd><i>Véase también artículo dedicado:</i> <a href="https://es.wikipedia.org/wiki/Ratio_de_entrop%C3%ADa" title="Ratio de entropía">Ratio de entropía</a></dd>
</dl>
<p><sup id="cite_ref-cover_7-1" class="reference separada"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_note-cover-7"><span class="corchete-llamada">[</span>5<span class="corchete-llamada">]</span></a></sup>​La <b>ratio de entropía</b> de una secuencia de n variables aleatorias (<a href="https://es.wikipedia.org/wiki/Proceso_estoc%C3%A1stico" title="Proceso estocástico">proceso estocástico</a>) caracteriza la tasa de crecimiento de la entropía de la secuencia con el crecimiento de n.</p>
<p>La <b>ratio de entropía</b> de un proceso estocástico <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{X_{i}\}}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/3ba8a662382c1f121e79e3f1d518c575cb6c42c6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.088ex; height:2.843ex;" alt="{\displaystyle \{X_{i}\}}"></span> viene definida por la ecuación:</p>
<blockquote style="padding: 5px 10px; background-color: white; color: black; text-align: left; margin-left:30px; margin-bottom: 0.4em; margin-top:0.2em; min-width:50%;">
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo movablelimits="true" form="prefix">lim</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
            <mo stretchy="false">→<!-- → --></mo>
            <mi mathvariant="normal">∞<!-- ∞ --></mi>
          </mrow>
        </munder>
        <mrow class="MJX-TeXAtom-ORD">
          <mstyle displaystyle="true" scriptlevel="0">
            <mfrac>
              <mn>1</mn>
              <mi>n</mi>
            </mfrac>
          </mstyle>
        </mrow>
        <mi>H</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle H(X)=\lim _{n\to \infty }{\dfrac {1}{n}}H(X_{1},...,X_{n})}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/38c477e55838abdcaeb2a0085ef9ddb63cb42a73" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.005ex; width:31.21ex; height:5.343ex;" alt="{\displaystyle H(X)=\lim _{n\to \infty }{\dfrac {1}{n}}H(X_{1},...,X_{n})}"></span></p>
</blockquote>
<p>siempre que dicho límite exista.</p>
<h2><span id="V.C3.A9ase_tambi.C3.A9n"></span><span class="mw-headline" id="Véase_también">Véase también</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=14" title="Editar sección: Véase también">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_cruzada" title="Entropía cruzada">Entropía cruzada</a></li>
<li><a href="https://es.wikipedia.org/wiki/Perplejidad" title="Perplejidad">Perplejidad</a></li>
<li><a href="https://es.wikipedia.org/wiki/Capacidad_de_canal" title="Capacidad de canal">Capacidad de canal</a></li>
<li><a href="https://es.wikipedia.org/wiki/Neguentrop%C3%ADa" title="Neguentropía">Neguentropía o Sintropía</a> Antónimo de entropía</li>
</ul>
<h2><span class="mw-headline" id="Notas_y_eferencias">Notas y eferencias</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=15" title="Editar sección: Notas y eferencias">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="listaref" style="list-style-type: lower-alpha;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-1"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">Obsérvese que se usa el logaritmo en base 2 porque se considera que la información se va a representar mediante código binario (se quiere representar con <a href="https://es.wikipedia.org/wiki/Bit" title="Bit">bits</a>). Si para representar la información se usaran valores en una base <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>a</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle a}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/ffd2487510aa438433a2579450ab2b3d557e5edc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.24ex; height:1.676ex;" alt="a"></span> entonces sería conveniente utilizar el logaritmo en base <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>a</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle a}</annotation>
  </semantics>
</math></span><img src="./Entropía (información)_files/ffd2487510aa438433a2579450ab2b3d557e5edc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.24ex; height:1.676ex;" alt="a"></span>.</span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-3"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">Obsérvese que es una cantidad adimensional, es decir no lleva unidad.</span></li>
</ol>
</div>
<h3><span class="mw-headline" id="Referencias">Referencias</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=16" title="Editar sección: Referencias">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="listaref" style="-moz-column-count:2; -webkit-column-count:2; column-count:2; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-2"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-2"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">Cuevas Agustín, Gonzalo, "Teoría de la información, codificación y lenguajes", Ed. SEPA (Sociedad para Estudios Pedagógicos Argentinos), Serie Informática 1986</span></li>
<li id="cite_note-4"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-4"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">Dan C. Marinescu, Gabriela M. Marinescu, "Classical and Quantum Information",Academic Press 2012</span></li>
<li id="cite_note-5"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-5"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">Huffman, D., "A method for the Construction of Minimum-Redundancy Codes", Proc. IRE, Vol 40 1952</span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-6"><span class="cite-accessibility-label">Volver arriba </span>↑</a></span> <span class="reference-text">"Applied cryptology, cryptographic protocols and computer security models", Richard A. DeMillo et al. American Mathematical Society 1983</span></li>
<li id="cite_note-cover-7"><span class="mw-cite-backlink">↑ <a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-cover_7-0"><span class="cite-accessibility-label">Saltar a: </span><sup><i><b>a</b></i></sup></a> <a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#cite_ref-cover_7-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Thomas M. Cover, Joy A. Thomas,"Elements of Information Theory", John Wiley &amp; Sons. Second Edition 2006</span></li>
</ol>
</div>
<h3><span id="Bibliograf.C3.ADa"></span><span class="mw-headline" id="Bibliografía">Bibliografía</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=17" title="Editar sección: Bibliografía">editar</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li>Jorge Ramió Aguirre, Aplicaciones criptográficas. Libro guía de la asignatura de Seguridad Informática. Escuela Universitaria de Informática. Universidad Politécnica de Madrid. Enero de 1998.</li>
</ul>
<h2><span class="mw-headline" id="Enlaces_externos">Enlaces externos</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit&amp;section=18" title="Editar sección: Enlaces externos">editar</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://cm.bell-labs.com/cm/ms/what/shannonday/paper.html">Una Teoría Matemática de la Comunicación</a> (en inglés)</li>
<li><a rel="nofollow" class="external text" href="http://www.shannonentropy.netmark.pl/">Calculadora de la entropía de Shannon</a> (en inglés)</li>
<li><a rel="nofollow" class="external text" href="http://ncomputers.org/entropytest">Calculadora de la entropía de Shannon para archivos</a> (en inglés)</li>
</ul>


<!-- 
NewPP limit report
Parsed by mw1238
Cached time: 20171205183442
Cache expiry: 1900800
Dynamic content: false
CPU time usage: 0.124 seconds
Real time usage: 0.353 seconds
Preprocessor visited node count: 836/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 3135/2097152 bytes
Template argument size: 720/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/500
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   28.259      1 -total
 28.01%    7.915      2 Plantilla:Listaref
 20.63%    5.830      9 Plantilla:Ecuación
 12.53%    3.540      9 Plantilla:Trim
  7.04%    1.990      1 Plantilla:Otros_usos
-->
</div>
<!-- Saved in parser cache with key eswiki:pcache:idhash:1166274-0!canonical!math=5 and timestamp 20171205183441 and revision id 103374672
 -->
<noscript>&lt;img src="//es.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /&gt;</noscript></div>					<div class="printfooter">
						Obtenido de «<a dir="ltr" href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;oldid=103374672">https://es.wikipedia.org/w/index.php?title=Entropía_(información)&amp;oldid=103374672</a>»					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="https://es.wikipedia.org/wiki/Especial:Categor%C3%ADas" title="Especial:Categorías">Categorías</a>: <ul><li><a href="https://es.wikipedia.org/wiki/Categor%C3%ADa:Entrop%C3%ADa_de_la_informaci%C3%B3n" title="Categoría:Entropía de la información">Entropía de la información</a></li><li><a href="https://es.wikipedia.org/wiki/Categor%C3%ADa:Teor%C3%ADa_de_la_informaci%C3%B3n" title="Categoría:Teoría de la información">Teoría de la información</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Menú de navegación</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Herramientas personales</h3>
						<ul>
							<li id="pt-anonuserpage">No has iniciado sesión</li><li id="pt-anontalk"><a href="https://es.wikipedia.org/wiki/Especial:MiDiscusi%C3%B3n" title="Discusión sobre ediciones hechas desde esta dirección IP [alt-shift-n]" accesskey="n">Discusión</a></li><li id="pt-anoncontribs"><a href="https://es.wikipedia.org/wiki/Especial:MisContribuciones" title="Una lista de modificaciones hechas desde esta dirección IP [alt-shift-y]" accesskey="y">Contribuciones</a></li><li id="pt-createaccount"><a href="https://es.wikipedia.org/w/index.php?title=Especial:Crear_una_cuenta&amp;returnto=Entrop%C3%ADa+%28informaci%C3%B3n%29" title="Te recomendamos crear una cuenta e iniciar sesión; sin embargo, no es obligatorio">Crear una cuenta</a></li><li id="pt-login"><a href="https://es.wikipedia.org/w/index.php?title=Especial:Entrar&amp;returnto=Entrop%C3%ADa+%28informaci%C3%B3n%29" title="Te recomendamos iniciar sesión, aunque no es obligatorio [alt-shift-o]" accesskey="o">Acceder</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Espacios de nombres</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)" title="Ver la página de contenido [alt-shift-c]" accesskey="c">Artículo</a></span></li><li id="ca-talk"><span><a href="https://es.wikipedia.org/wiki/Discusi%C3%B3n:Entrop%C3%ADa_(informaci%C3%B3n)" rel="discussion" title="Discusión acerca del artículo [alt-shift-t]" accesskey="t">Discusión</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<h3 id="p-variants-label" tabindex="0">
							<span>Variantes</span>
						</h3>
						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Vistas</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)">Leer</a></span></li><li id="ca-edit" class="collapsible"><span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=edit" title="Editar esta página [alt-shift-e]" accesskey="e">Editar</a></span></li><li id="ca-history" class="collapsible"><span><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=history" title="Versiones anteriores de esta página [alt-shift-h]" accesskey="h">Ver historial</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label" style="">
						<h3 id="p-cactions-label" tabindex="0"><span>Más</span></h3>
						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Buscar</label>
						</h3>
						<form action="https://es.wikipedia.org/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Buscar en Wikipedia" title="Buscar en este wiki [alt-shift-f]" accesskey="f" id="searchInput" tabindex="1" autocomplete="off"><input type="hidden" value="Especial:Buscar" name="title"><input type="submit" name="go" value="Ir" title="Ir a la página con este nombre exacto si existe" id="searchButton" class="searchButton">							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="https://es.wikipedia.org/wiki/Wikipedia:Portada" title="Visitar la página principal"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navegación</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="https://es.wikipedia.org/wiki/Wikipedia:Portada" title="Visitar la página principal [alt-shift-z]" accesskey="z">Portada</a></li><li id="n-portal"><a href="https://es.wikipedia.org/wiki/Portal:Comunidad" title="Acerca del proyecto, lo que puedes hacer, dónde encontrar información">Portal de la comunidad</a></li><li id="n-currentevents"><a href="https://es.wikipedia.org/wiki/Portal:Actualidad" title="Encuentra información de contexto sobre acontecimientos actuales">Actualidad</a></li><li id="n-recentchanges"><a href="https://es.wikipedia.org/wiki/Especial:CambiosRecientes" title="Lista de cambios recientes en el wiki [alt-shift-r]" accesskey="r">Cambios recientes</a></li><li id="n-newpages"><a href="https://es.wikipedia.org/wiki/Especial:P%C3%A1ginasNuevas">Páginas nuevas</a></li><li id="n-randompage"><a href="https://es.wikipedia.org/wiki/Especial:Aleatoria" title="Cargar una página al azar [alt-shift-x]" accesskey="x">Página aleatoria</a></li><li id="n-help"><a href="https://es.wikipedia.org/wiki/Ayuda:Contenidos" title="El lugar para aprender">Ayuda</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_es.wikipedia.org&amp;uselang=es" title="Apóyanos">Donaciones</a></li><li id="n-bug_in_article"><a href="https://es.wikipedia.org/wiki/Wikipedia:Informes_de_error">Notificar un error</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Imprimir/exportar</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="https://es.wikipedia.org/w/index.php?title=Especial:Libro&amp;bookcmd=book_creator&amp;referer=Entrop%C3%ADa+%28informaci%C3%B3n%29">Crear un libro</a></li><li id="coll-download-as-rdf2latex"><a href="https://es.wikipedia.org/w/index.php?title=Especial:ElectronPdf&amp;page=Entrop%C3%ADa+%28informaci%C3%B3n%29&amp;action=show-download-screen">Descargar como PDF</a></li><li id="t-print"><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;printable=yes" title="Versión imprimible de esta página [alt-shift-p]" accesskey="p">Versión para imprimir</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-wikibase-otherprojects" aria-labelledby="p-wikibase-otherprojects-label">
			<h3 id="p-wikibase-otherprojects-label">En otros proyectos</h3>
			<div class="body">
								<ul>
					<li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Entropy_and_information" hreflang="en">Wikimedia Commons</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Herramientas</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="https://es.wikipedia.org/wiki/Especial:LoQueEnlazaAqu%C3%AD/Entrop%C3%ADa_(informaci%C3%B3n)" title="Lista de todas las páginas del wiki que enlazan aquí [alt-shift-j]" accesskey="j">Lo que enlaza aquí</a></li><li id="t-recentchangeslinked"><a href="https://es.wikipedia.org/wiki/Especial:CambiosEnEnlazadas/Entrop%C3%ADa_(informaci%C3%B3n)" rel="nofollow" title="Cambios recientes en las páginas que enlazan con esta [alt-shift-k]" accesskey="k">Cambios en enlazadas</a></li><li id="t-upload"><a href="https://commons.wikimedia.org/wiki/Special:UploadWizard?uselang=es" title="Subir archivos [alt-shift-u]" accesskey="u">Subir archivo</a></li><li id="t-specialpages"><a href="https://es.wikipedia.org/wiki/Especial:P%C3%A1ginasEspeciales" title="Lista de todas las páginas especiales [alt-shift-q]" accesskey="q">Páginas especiales</a></li><li id="t-permalink"><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;oldid=103374672" title="Enlace permanente a esta versión de la página">Enlace permanente</a></li><li id="t-info"><a href="https://es.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;action=info" title="Más información sobre esta página">Información de la página</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q204570" title="Enlace al elemento conectado del repositorio de datos [alt-shift-g]" accesskey="g">Elemento de Wikidata</a></li><li id="t-cite"><a href="https://es.wikipedia.org/w/index.php?title=Especial:Citar&amp;page=Entrop%C3%ADa_%28informaci%C3%B3n%29&amp;id=103374672" title="Información sobre cómo citar esta página">Citar esta página</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label"><span class="uls-settings-trigger" title="Opciones de idioma" tabindex="0" role="button" aria-haspopup="true"></span>
			<h3 id="p-lang-label">En otros idiomas</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-ar" style=""><a href="https://ar.wikipedia.org/wiki/%D8%A7%D8%B9%D8%AA%D9%84%D8%A7%D8%AC_(%D9%85%D8%B9%D9%84%D9%88%D9%85%D8%A7%D8%AA)" title="اعتلاج (معلومات) (árabe)" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-bar" style="display: none;"><a href="https://bar.wikipedia.org/wiki/Entropie_(Informationstheorie)" title="Entropie (Informationstheorie) (Bavarian)" lang="bar" hreflang="bar" class="interlanguage-link-target">Boarisch</a></li><li class="interlanguage-link interwiki-bg" style="display: none;"><a href="https://bg.wikipedia.org/wiki/%D0%95%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F_%D0%BD%D0%B0_%D0%A8%D0%B0%D0%BD%D1%8A%D0%BD" title="Ентропия на Шанън (búlgaro)" lang="bg" hreflang="bg" class="interlanguage-link-target">Български</a></li><li class="interlanguage-link interwiki-bs" style="display: none;"><a href="https://bs.wikipedia.org/wiki/Entropija_(teorija_informacija)" title="Entropija (teorija informacija) (bosnio)" lang="bs" hreflang="bs" class="interlanguage-link-target">Bosanski</a></li><li class="interlanguage-link interwiki-ca" style=""><a href="https://ca.wikipedia.org/wiki/Entropia_de_Shannon" title="Entropia de Shannon (catalán)" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-ckb" style="display: none;"><a href="https://ckb.wikipedia.org/wiki/%D8%A6%D8%A7%D9%86%D8%AA%D8%B1%DB%86%D9%BE%DB%8C%DB%8C_%D8%B2%D8%A7%D9%86%DB%8C%D8%A7%D8%B1%DB%8C" title="ئانترۆپیی زانیاری (kurdo sorani)" lang="ckb" hreflang="ckb" class="interlanguage-link-target">کوردی</a></li><li class="interlanguage-link interwiki-cy" style="display: none;"><a href="https://cy.wikipedia.org/wiki/Entropi_gwybodaeth" title="Entropi gwybodaeth (galés)" lang="cy" hreflang="cy" class="interlanguage-link-target">Cymraeg</a></li><li class="interlanguage-link interwiki-da" style="display: none;"><a href="https://da.wikipedia.org/wiki/Entropi_(informationsteori)" title="Entropi (informationsteori) (danés)" lang="da" hreflang="da" class="interlanguage-link-target">Dansk</a></li><li class="interlanguage-link interwiki-de" style="display: none;"><a href="https://de.wikipedia.org/wiki/Entropie_(Informationstheorie)" title="Entropie (Informationstheorie) (alemán)" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-el" style="display: none;"><a href="https://el.wikipedia.org/wiki/%CE%95%CE%BD%CF%84%CF%81%CE%BF%CF%80%CE%AF%CE%B1_%CF%80%CE%BB%CE%B7%CF%81%CE%BF%CF%86%CE%BF%CF%81%CE%B9%CF%8E%CE%BD" title="Εντροπία πληροφοριών (griego)" lang="el" hreflang="el" class="interlanguage-link-target">Ελληνικά</a></li><li class="interlanguage-link interwiki-en" style=""><a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" title="Entropy (information theory) (inglés)" lang="en" hreflang="en" class="interlanguage-link-target">English</a></li><li class="interlanguage-link interwiki-fa" style="display: none;"><a href="https://fa.wikipedia.org/wiki/%D8%A2%D9%86%D8%AA%D8%B1%D9%88%D9%BE%DB%8C_%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA" title="آنتروپی اطلاعات (persa)" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr" style=""><a href="https://fr.wikipedia.org/wiki/Entropie_de_Shannon" title="Entropie de Shannon (francés)" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-gl" style=""><a href="https://gl.wikipedia.org/wiki/Entrop%C3%ADa_da_informaci%C3%B3n" title="Entropía da información (gallego)" lang="gl" hreflang="gl" class="interlanguage-link-target">Galego</a></li><li class="interlanguage-link interwiki-he" style="display: none;"><a href="https://he.wikipedia.org/wiki/%D7%90%D7%A0%D7%98%D7%A8%D7%95%D7%A4%D7%99%D7%94_(%D7%A1%D7%98%D7%98%D7%99%D7%A1%D7%98%D7%99%D7%A7%D7%94)" title="אנטרופיה (סטטיסטיקה) (hebreo)" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-hu" style="display: none;"><a href="https://hu.wikipedia.org/wiki/Shannon-entr%C3%B3piaf%C3%BCggv%C3%A9ny" title="Shannon-entrópiafüggvény (húngaro)" lang="hu" hreflang="hu" class="interlanguage-link-target">Magyar</a></li><li class="interlanguage-link interwiki-it" style="display: none;"><a href="https://it.wikipedia.org/wiki/Entropia_(teoria_dell%27informazione)" title="Entropia (teoria dell&#39;informazione) (italiano)" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-ja" style="display: none;"><a href="https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F" title="情報量 (japonés)" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-ko" style="display: none;"><a href="https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B3%B4_%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC" title="정보 엔트로피 (coreano)" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-lt" style="display: none;"><a href="https://lt.wikipedia.org/wiki/Entropija_(informacijos_teorija)" title="Entropija (informacijos teorija) (lituano)" lang="lt" hreflang="lt" class="interlanguage-link-target">Lietuvių</a></li><li class="interlanguage-link interwiki-mhr" style="display: none;"><a href="https://mhr.wikipedia.org/wiki/%D0%A8%D0%B5%D0%BD%D0%BD%D0%BE%D0%BD%D1%8B%D0%BD_%D1%84%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B6%D0%BE" title="Шеннонын формулжо (Eastern Mari)" lang="mhr" hreflang="mhr" class="interlanguage-link-target">Олык марий</a></li><li class="interlanguage-link interwiki-nl" style="display: none;"><a href="https://nl.wikipedia.org/wiki/Entropie_(informatietheorie)" title="Entropie (informatietheorie) (neerlandés)" lang="nl" hreflang="nl" class="interlanguage-link-target">Nederlands</a></li><li class="interlanguage-link interwiki-pa" style="display: none;"><a href="https://pa.wikipedia.org/wiki/%E0%A8%90%E0%A8%A8%E0%A8%9F%E0%A9%8D%E0%A8%B0%E0%A9%8C%E0%A8%AA%E0%A9%80_(%E0%A8%87%E0%A8%A8%E0%A8%AB%E0%A9%8D%E0%A8%B0%E0%A8%AE%E0%A9%87%E0%A8%B8%E0%A8%BC%E0%A8%A8_%E0%A8%A5%E0%A8%BF%E0%A8%8A%E0%A8%B0%E0%A9%80)" title="ਐਨਟ੍ਰੌਪੀ (ਇਨਫ੍ਰਮੇਸ਼ਨ ਥਿਊਰੀ) (panyabí)" lang="pa" hreflang="pa" class="interlanguage-link-target">ਪੰਜਾਬੀ</a></li><li class="interlanguage-link interwiki-pl" style="display: none;"><a href="https://pl.wikipedia.org/wiki/Entropia_(teoria_informacji)" title="Entropia (teoria informacji) (polaco)" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-pt" style=""><a href="https://pt.wikipedia.org/wiki/Entropia_da_informa%C3%A7%C3%A3o" title="Entropia da informação (portugués)" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ro" style="display: none;"><a href="https://ro.wikipedia.org/wiki/Entropie_informa%C8%9Bional%C4%83" title="Entropie informațională (rumano)" lang="ro" hreflang="ro" class="interlanguage-link-target">Română</a></li><li class="interlanguage-link interwiki-ru" style=""><a href="https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F" title="Информационная энтропия (ruso)" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-simple" style="display: none;"><a href="https://simple.wikipedia.org/wiki/Information_entropy" title="Information entropy (Simple English)" lang="simple" hreflang="simple" class="interlanguage-link-target">Simple English</a></li><li class="interlanguage-link interwiki-sk" style="display: none;"><a href="https://sk.wikipedia.org/wiki/Entropia_(te%C3%B3ria_inform%C3%A1ci%C3%AD)" title="Entropia (teória informácií) (eslovaco)" lang="sk" hreflang="sk" class="interlanguage-link-target">Slovenčina</a></li><li class="interlanguage-link interwiki-sl" style="display: none;"><a href="https://sl.wikipedia.org/wiki/Entropija_(informatika)" title="Entropija (informatika) (esloveno)" lang="sl" hreflang="sl" class="interlanguage-link-target">Slovenščina</a></li><li class="interlanguage-link interwiki-sr" style="display: none;"><a href="https://sr.wikipedia.org/wiki/%D0%95%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%98%D0%B0_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%98%D0%B0_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%98%D0%B0)" title="Ентропија (теорија информација) (serbio)" lang="sr" hreflang="sr" class="interlanguage-link-target">Српски / srpski</a></li><li class="interlanguage-link interwiki-su" style="display: none;"><a href="https://su.wikipedia.org/wiki/%C3%89ntropi_informasi" title="Éntropi informasi (sundanés)" lang="su" hreflang="su" class="interlanguage-link-target">Basa Sunda</a></li><li class="interlanguage-link interwiki-sv" style="display: none;"><a href="https://sv.wikipedia.org/wiki/Entropi_(informationsteori)" title="Entropi (informationsteori) (sueco)" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></li><li class="interlanguage-link interwiki-te" style="display: none;"><a href="https://te.wikipedia.org/wiki/%E0%B0%B8%E0%B0%AE%E0%B0%BE%E0%B0%9A%E0%B0%BE%E0%B0%B0_%E0%B0%B8%E0%B0%82%E0%B0%95%E0%B0%B0%E0%B0%A4_(%E0%B0%87%E0%B0%A8%E0%B1%8D%E0%B0%AB%E0%B0%B0%E0%B1%8D%E0%B0%AE%E0%B1%87%E0%B0%B7%E0%B0%A8%E0%B1%8D_%E0%B0%8E%E0%B0%82%E0%B0%9F%E0%B1%8D%E0%B0%B0%E0%B1%8A%E0%B0%AA%E0%B1%80)" title="సమాచార సంకరత (ఇన్ఫర్మేషన్ ఎంట్రొపీ) (telugu)" lang="te" hreflang="te" class="interlanguage-link-target">తెలుగు</a></li><li class="interlanguage-link interwiki-th" style="display: none;"><a href="https://th.wikipedia.org/wiki/%E0%B9%80%E0%B8%AD%E0%B8%99%E0%B9%82%E0%B8%97%E0%B8%A3%E0%B8%9B%E0%B8%B5%E0%B8%82%E0%B8%AD%E0%B8%87%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%A1%E0%B8%B9%E0%B8%A5" title="เอนโทรปีของข้อมูล (tailandés)" lang="th" hreflang="th" class="interlanguage-link-target">ไทย</a></li><li class="interlanguage-link interwiki-tr" style="display: none;"><a href="https://tr.wikipedia.org/wiki/Entropi_(bilgi_kuram%C4%B1)" title="Entropi (bilgi kuramı) (turco)" lang="tr" hreflang="tr" class="interlanguage-link-target">Türkçe</a></li><li class="interlanguage-link interwiki-uk" style="display: none;"><a href="https://uk.wikipedia.org/wiki/%D0%86%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D1%96%D0%B9%D0%BD%D0%B0_%D0%B5%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D1%96%D1%8F" title="Інформаційна ентропія (ucraniano)" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-ur" style=""><a href="https://ur.wikipedia.org/wiki/%D8%AF%D8%B1%D9%85%D8%A7%D8%A6%D9%84%D8%AA_(%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA%DB%8C_%D9%86%D8%B8%D8%B1%DB%8C%DB%81)" title="درمائلت (اطلاعاتی نظریہ) (urdu)" lang="ur" hreflang="ur" class="interlanguage-link-target">اردو</a></li><li class="interlanguage-link interwiki-vi" style="display: none;"><a href="https://vi.wikipedia.org/wiki/Entropy_th%C3%B4ng_tin" title="Entropy thông tin (vietnamita)" lang="vi" hreflang="vi" class="interlanguage-link-target">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh" style=""><a href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)" title="熵 (信息论) (chino)" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li>				<button class="mw-interlanguage-selector mw-ui-button" title="Todos los idiomas (selección inicial de opciones comunes tuyas y de otros)">31 más</button></ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q204570#sitelinks-wikipedia" title="Editar enlaces interlingüísticos" class="wbc-editpage">Editar enlaces</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> Se editó esta página por última vez el 13 nov 2017 a las 12:37.</li>
								<li id="footer-info-copyright">El texto está disponible bajo la <a rel="license" href="https://es.wikipedia.org/wiki/Wikipedia:Texto_de_la_Licencia_Creative_Commons_Atribuci%C3%B3n-CompartirIgual_3.0_Unported">Licencia Creative Commons Atribución Compartir Igual&nbsp;3.0</a><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
pueden aplicarse cláusulas adicionales. Al usar este sitio, usted acepta nuestros <a href="https://wikimediafoundation.org/wiki/Terms_of_Use">términos de uso</a> y nuestra <a href="https://wikimediafoundation.org/wiki/Privacy_policy">política de privacidad</a>. <br>Wikipedia® es una marca registrada de la <a href="https://www.wikimediafoundation.org/">Fundación Wikimedia, Inc.</a>, una organización sin ánimo de lucro.</li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://meta.wikimedia.org/wiki/Privacy_policy/es" class="extiw" title="m:Privacy policy/es">Normativa de privacidad</a></li>
								<li id="footer-places-about"><a href="https://es.wikipedia.org/wiki/Wikipedia:Acerca_de" title="Wikipedia:Acerca de">Acerca de Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="https://es.wikipedia.org/wiki/Wikipedia:Limitaci%C3%B3n_general_de_responsabilidad" title="Wikipedia:Limitación general de responsabilidad">Limitación de responsabilidad</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Desarrolladores</a></li>
								<li id="footer-places-cookiestatement"><a href="https://wikimediafoundation.org/wiki/Cookie_statement/es">Declaración de cookies</a></li>
								<li id="footer-places-mobileview"><a href="https://es.m.wikipedia.org/w/index.php?title=Entrop%C3%ADa_(informaci%C3%B3n)&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Versión para móviles</a></li>
							<li style="display: none;"><a href="https://es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)#">Activar previsualizaciones</a></li></ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="./Entropía (información)_files/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"></a>					</li>
										<li id="footer-poweredbyico">
						<a href="https://www.mediawiki.org/"><img src="./Entropía (información)_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.124","walltime":"0.353","ppvisitednodes":{"value":836,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":3135,"limit":2097152},"templateargumentsize":{"value":720,"limit":2097152},"expansiondepth":{"value":5,"limit":40},"expensivefunctioncount":{"value":0,"limit":500},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%   28.259      1 -total"," 28.01%    7.915      2 Plantilla:Listaref"," 20.63%    5.830      9 Plantilla:Ecuación"," 12.53%    3.540      9 Plantilla:Trim","  7.04%    1.990      1 Plantilla:Otros_usos"]},"cachereport":{"origin":"mw1238","timestamp":"20171205183442","ttl":1900800,"transientcontent":false}}});});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":89,"wgHostname":"mw1319"});});</script>
	

<div class="suggestions" style="display: none; font-size: 13px;"><div class="suggestions-results"></div><div class="suggestions-special"></div></div><div id="mwe-popups-svg"><svg width="0" height="0"><defs><clippath id="mwe-popups-mask"><polygon points="0 8, 10 8, 18 0, 26 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-mask-flip"><polygon points="0 8, 274 8, 282 0, 290 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-landscape-mask"><polygon points="0 8, 174 8, 182 0, 190 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-landscape-mask-flip"><polygon points="0 0, 1000 0, 1000 242, 190 242, 182 250, 174 242, 0 242"></polygon></clippath></defs></svg></div></body></html>